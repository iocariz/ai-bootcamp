{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ffbdb4-3835-46da-ae1f-0cd41723aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fe8f391-46bb-42ae-a431-0742c2dfd281",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b2e1a7-0d59-4e18-8abd-0e811dbcb3b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**The Starry Night Unicorn**\n",
      "\n",
      "Once upon a time, in a magical forest filled with sparkling flowers and whispering trees, there lived a gentle unicorn named Luna. Her coat shimmered like the moonlight, and her horn glowed softly, illuminating the paths she trotted.\n",
      "\n",
      "Every evening, as the sun dipped beyond the horizon, Luna would watch the stars twinkle into existence. She believed that each star held a special wish, waiting for someone to believe. But Luna had a secret: she had never made a wish of her own.\n",
      "\n",
      "One night, when the sky was particularly bright, Luna spotted a little girl named Mia, who had climbed a tall hill to see the stars. Mia looked sad, and Luna trotted over, her horn glowing softly. \n",
      "\n",
      "“Hello, little one,” Luna said gently. “Why do you look so sad?”\n",
      "\n",
      "Mia sighed. “I wished for a friend to share the stars with, but I’m all alone.”\n",
      "\n",
      "Luna’s heart felt warm. She lowered her head and said, “Close your eyes and make a wish.”\n",
      "\n",
      "Mia closed her eyes tightly and whispered her wish to the stars. “I wish I could have a friend forever.”\n",
      "\n",
      "With a shimmer of her horn, Luna made a wish of her own. “I wish to be her friend.”\n",
      "\n",
      "Suddenly, a burst of stardust filled the air, and as it settled, Mia opened her eyes. There, standing before her, was Luna, the unicorn.\n",
      "\n",
      "Mia gasped in delight. “You’re real!”\n",
      "\n",
      "“Indeed I am. And I’d love to be your friend!” Luna replied.\n",
      "\n",
      "From that night on, the two shared countless adventures under the stars. They chased fireflies, danced in the moonlight, and whispered secrets to the night. They discovered that wishes aren’t just for stars; they can come true when shared with someone special.\n",
      "\n",
      "And as the stars twinkled above, Luna and Mia knew that they had each other, a bond as bright as the night sky. \n",
      "\n",
      "With hearts full of joy, they settled down under the stars, and drifted off to sleep, knowing that every wish could lead to a beautiful friendship.\n",
      "\n",
      "And so, the moonlight glowed a little brighter, and the stars sparkled a little more, forever holding their dreams.\n",
      "\n",
      "**The End.**\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=\"Write a short bedtime story about a unicorn\"\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e22b9d6-0ff5-4bbc-a4d1-cf6238cb154f",
   "metadata": {},
   "source": [
    "We typically use messages for that instead of putting everything in just one string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb6b251d-7776-47ba-a7a3-91b203d4372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"tell me a joke about Alexey\"}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905ed630-fecd-405d-81a4-8a55196f0852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"resp_07e68293d482dc7f0068e73fdfde20819b938ce32f7b90e525\",\n",
      "  \"created_at\": 1759985631.0,\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"metadata\": {},\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"object\": \"response\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_07e68293d482dc7f0068e73fe14418819b91eab71a77e96641\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"annotations\": [],\n",
      "          \"text\": \"Why did Alexey bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!\",\n",
      "          \"type\": \"output_text\",\n",
      "          \"logprobs\": []\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\",\n",
      "      \"status\": \"completed\",\n",
      "      \"type\": \"message\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_p\": 1.0,\n",
      "  \"background\": false,\n",
      "  \"conversation\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"generate_summary\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"status\": \"completed\",\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"top_logprobs\": 0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 14,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 22,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 36\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"store\": true\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(response.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a713d9b-0af2-4626-b354-5b503b547956",
   "metadata": {},
   "source": [
    "What is interesting here:\n",
    "\n",
    "* output - everything that the LLM returned\n",
    "\n",
    "* usage - how many tokens we used (also - how much we paid)\n",
    "\n",
    "Getting the text:\n",
    "\n",
    "* response.output[0].content[0].text\n",
    "\n",
    "* response.output_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d0001-2bc2-4651-bc7a-aab9f4ec4d22",
   "metadata": {},
   "source": [
    "We can stream the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8eb9e47-94d0-4c7f-9780-523c72f0b1e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseCreatedEvent(response=Response(id='resp_0f253b3c9d667a710068e74082470c819b84e150799b5f7988', created_at=1759985794.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=0, type='response.created')\n",
      "ResponseInProgressEvent(response=Response(id='resp_0f253b3c9d667a710068e74082470c819b84e150799b5f7988', created_at=1759985794.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='auto', status='in_progress', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=None, user=None, store=True), sequence_number=1, type='response.in_progress')\n",
      "ResponseOutputItemAddedEvent(item=ResponseOutputMessage(id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', content=[], role='assistant', status='in_progress', type='message'), output_index=0, sequence_number=2, type='response.output_item.added')\n",
      "ResponseContentPartAddedEvent(content_index=0, item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', output_index=0, part=ResponseOutputText(annotations=[], text='', type='output_text', logprobs=[]), sequence_number=3, type='response.content_part.added')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='Why', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=4, type='response.output_text.delta', obfuscation='yqfBlEdoFTp2S')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' did', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=5, type='response.output_text.delta', obfuscation='d0t3pkRcCmVk')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' Alex', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=6, type='response.output_text.delta', obfuscation='IQ36TvuISkU')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='ey', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=7, type='response.output_text.delta', obfuscation='JHTlOe5dQqM7lK')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bring', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=8, type='response.output_text.delta', obfuscation='A8BFKDEJXO')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' a', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=9, type='response.output_text.delta', obfuscation='1fu5fT82G6wueK')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' ladder', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=10, type='response.output_text.delta', obfuscation='BgZbuk3xb')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' to', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=11, type='response.output_text.delta', obfuscation='Xi5JArRVW5uQ3')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' the', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=12, type='response.output_text.delta', obfuscation='9rXK4sKkWHUI')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' bar', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=13, type='response.output_text.delta', obfuscation='TB283dNgMgwE')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='?\\n\\n', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=14, type='response.output_text.delta', obfuscation='NRkNt99PYQND9')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='Because', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=15, type='response.output_text.delta', obfuscation='x1ke5RUWc')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' he', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=16, type='response.output_text.delta', obfuscation='jVymYsTnlSHUT')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' heard', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=17, type='response.output_text.delta', obfuscation='HidjilNBWd')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' the', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=18, type='response.output_text.delta', obfuscation='JG8me0fjEIKZ')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' drinks', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=19, type='response.output_text.delta', obfuscation='GDDsMFDo2')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' were', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=20, type='response.output_text.delta', obfuscation='LmPGvqVHgiy')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' on', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=21, type='response.output_text.delta', obfuscation='ESqTU9QWDFjT9')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' the', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=22, type='response.output_text.delta', obfuscation='y6WjCffR9Q2T')\n",
      "ResponseTextDeltaEvent(content_index=0, delta=' house', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=23, type='response.output_text.delta', obfuscation='1anSclBFpC')\n",
      "ResponseTextDeltaEvent(content_index=0, delta='!', item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=24, type='response.output_text.delta', obfuscation='ucjQnACVD9hVpyU')\n",
      "ResponseTextDoneEvent(content_index=0, item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', logprobs=[], output_index=0, sequence_number=25, text='Why did Alexey bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!', type='response.output_text.done')\n",
      "ResponseContentPartDoneEvent(content_index=0, item_id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', output_index=0, part=ResponseOutputText(annotations=[], text='Why did Alexey bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!', type='output_text', logprobs=[]), sequence_number=26, type='response.content_part.done')\n",
      "ResponseOutputItemDoneEvent(item=ResponseOutputMessage(id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', content=[ResponseOutputText(annotations=[], text='Why did Alexey bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message'), output_index=0, sequence_number=27, type='response.output_item.done')\n",
      "ResponseCompletedEvent(response=Response(id='resp_0f253b3c9d667a710068e74082470c819b84e150799b5f7988', created_at=1759985794.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4o-mini-2024-07-18', object='response', output=[ResponseOutputMessage(id='msg_0f253b3c9d667a710068e740835fe8819b9610db653833b747', content=[ResponseOutputText(annotations=[], text='Why did Alexey bring a ladder to the bar?\\n\\nBecause he heard the drinks were on the house!', type='output_text', logprobs=[])], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='auto', tools=[], top_p=1.0, background=False, conversation=None, max_output_tokens=None, max_tool_calls=None, previous_response_id=None, prompt=None, prompt_cache_key=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), safety_identifier=None, service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text'), verbosity='medium'), top_logprobs=0, truncation='disabled', usage=ResponseUsage(input_tokens=14, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=22, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=36), user=None, store=True), sequence_number=28, type='response.completed')\n"
     ]
    }
   ],
   "source": [
    "stream = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for event in stream:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "491d0614-30d9-4374-8f2a-5d926f88d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in stream:\n",
    "    if hasattr(event, 'delta'):\n",
    "        print(event.delta, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bc2b863-67ce-4bbc-bba5-aa6b8be42d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! But first, what's your name?\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You're an assistant that can make jokes. Always find out the name of\n",
    "the person to make the jokes personalized. Once you know the name,\n",
    "make the joke about them.\n",
    "\"\"\".strip()\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"developer\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": \"tell me a joke\"}\n",
    "]\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6413168-c6e3-4f0b-951e-ee9dcb2a1ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice to meet you, Iñigo! Here’s one for you:\n",
      "\n",
      "Why did Iñigo bring a pencil to the party?\n",
      "\n",
      "Because he wanted to draw some attention!\n"
     ]
    }
   ],
   "source": [
    "messages.append(response.output[0])\n",
    "messages.append({\"role\": \"user\", \"content\": \"Iñigo\"})\n",
    "\n",
    "response = openai_client.responses.create(\n",
    "    model='gpt-4o-mini',\n",
    "    input=messages\n",
    ")\n",
    "\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb352690-fea5-4ad1-9e15-e1d38f61dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: Iñigo\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <div><b>Assistant:</b></div>\n",
       "                <div><p>Great to meet you, Iñigo! Here’s a joke just for you:</p>\n",
       "<p>Why did Iñigo bring a ladder to the bar?</p>\n",
       "<p>Because he heard the drinks were on the house!</p>\n",
       "</div>\n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "You: stop\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "from toyaikit.llm import OpenAIClient\n",
    "from toyaikit.chat import IPythonChatInterface\n",
    "from toyaikit.chat.runners import OpenAIResponsesRunner\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "you're an assistant that can make jokes. Always find out the name of\n",
    "the person to make the jokes personalized. Once you know the name,\n",
    "make the joke about them.\n",
    "\"\"\".strip()\n",
    "\n",
    "llm_client = OpenAIClient(\n",
    "    model='gpt-4o-mini',\n",
    "    client=openai_client\n",
    ")\n",
    "\n",
    "runner = OpenAIResponsesRunner(\n",
    "    tools=None,\n",
    "    developer_prompt=system_prompt,\n",
    "    chat_interface=IPythonChatInterface(),\n",
    "    llm_client=llm_client\n",
    ")\n",
    "\n",
    "runner.run();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236453bd-27f7-49e3-b266-ac33ac93707d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
