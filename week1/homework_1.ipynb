{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minsearch import Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from typing import Iterable, Callable\n",
    "import zipfile\n",
    "import traceback\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RawRepositoryFile:\n",
    "    filename: str\n",
    "    content: str\n",
    "\n",
    "class GithubRepositoryDataReader:\n",
    "    \"\"\"\n",
    "    Downloads and parses markdown and code files from a GitHub repository.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                repo_owner: str,\n",
    "                repo_name: str,\n",
    "                allowed_extensions: Iterable[str] | None = None,\n",
    "                filename_filter: Callable[[str], bool] | None = None\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initialize the GitHub repository data reader.\n",
    "        \n",
    "        Args:\n",
    "            repo_owner: The owner/organization of the GitHub repository\n",
    "            repo_name: The name of the GitHub repository\n",
    "            allowed_extensions: Optional set of file extensions to include\n",
    "                    (e.g., {\"md\", \"py\"}). If not provided, all file types are included\n",
    "            filename_filter: Optional callable to filter files by their path\n",
    "        \"\"\"\n",
    "        prefix = \"https://codeload.github.com\"\n",
    "        self.url = (\n",
    "            f\"{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main\"\n",
    "        )\n",
    "\n",
    "        if allowed_extensions is not None:\n",
    "            self.allowed_extensions = {ext.lower() for ext in allowed_extensions}\n",
    "\n",
    "        if filename_filter is None:\n",
    "            self.filename_filter = lambda filepath: True\n",
    "        else:\n",
    "            self.filename_filter = filename_filter\n",
    "\n",
    "    def read(self) -> list[RawRepositoryFile]:\n",
    "        \"\"\"\n",
    "        Download and extract files from the GitHub repository.\n",
    "        \n",
    "        Returns:\n",
    "            List of RawRepositoryFile objects for each processed file\n",
    "            \n",
    "        Raises:\n",
    "            Exception: If the repository download fails\n",
    "        \"\"\"\n",
    "        resp = requests.get(self.url)\n",
    "        if resp.status_code != 200:\n",
    "            raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "        zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "        repository_data = self._extract_files(zf)\n",
    "        zf.close()\n",
    "\n",
    "        return repository_data\n",
    "\n",
    "    def _extract_files(self, zf: zipfile.ZipFile) -> list[RawRepositoryFile]:\n",
    "        \"\"\"\n",
    "        Extract and process files from the zip archive.\n",
    "        \n",
    "        Args:\n",
    "            zf: ZipFile object containing the repository data\n",
    "\n",
    "        Returns:\n",
    "            List of RawRepositoryFile objects for each processed file\n",
    "        \"\"\"\n",
    "        data = []\n",
    "\n",
    "        for file_info in zf.infolist():\n",
    "            filepath = self._normalize_filepath(file_info.filename)\n",
    "\n",
    "            if self._should_skip_file(filepath):\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with zf.open(file_info) as f_in:\n",
    "                    content = f_in.read().decode(\"utf-8\", errors=\"ignore\")\n",
    "                    if content is not None:\n",
    "                        content = content.strip()\n",
    "\n",
    "                    file = RawRepositoryFile(\n",
    "                        filename=filepath,\n",
    "                        content=content\n",
    "                    )\n",
    "                    data.append(file)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_info.filename}: {e}\")\n",
    "                traceback.print_exc()\n",
    "                continue\n",
    "\n",
    "        return data\n",
    "\n",
    "    def _should_skip_file(self, filepath: str) -> bool:\n",
    "        \"\"\"\n",
    "        Determine whether a file should be skipped during processing.\n",
    "        \n",
    "        Args:\n",
    "            filepath: The file path to check\n",
    "            \n",
    "        Returns:\n",
    "            True if the file should be skipped, False otherwise\n",
    "        \"\"\"\n",
    "        filepath = filepath.lower()\n",
    "\n",
    "        # directory\n",
    "        if filepath.endswith(\"/\"):\n",
    "            return True\n",
    "\n",
    "        # hidden file\n",
    "        filename = filepath.split(\"/\")[-1]\n",
    "        if filename.startswith(\".\"):\n",
    "            return True\n",
    "\n",
    "        if self.allowed_extensions:\n",
    "            ext = self._get_extension(filepath)\n",
    "            if ext not in self.allowed_extensions:\n",
    "                return True\n",
    "\n",
    "        if not self.filename_filter(filepath):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _get_extension(self, filepath: str) -> str:\n",
    "        \"\"\"\n",
    "        Extract the file extension from a filepath.\n",
    "        \n",
    "        Args:\n",
    "            filepath: The file path to extract extension from\n",
    "            \n",
    "        Returns:\n",
    "            The file extension (without dot) or empty string if no extension\n",
    "        \"\"\"\n",
    "        filename = filepath.lower().split(\"/\")[-1]\n",
    "        if \".\" in filename:\n",
    "            return filename.rsplit(\".\", maxsplit=1)[-1]\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def _normalize_filepath(self, filepath: str) -> str:\n",
    "        \"\"\"\n",
    "        Removes the top-level directory from the file path inside the zip archive.\n",
    "        'repo-main/path/to/file.py' -> 'path/to/file.py'\n",
    "        \n",
    "        Args:\n",
    "            filepath: The original filepath from the zip archive\n",
    "            \n",
    "        Returns:\n",
    "            The normalized filepath with top-level directory removed\n",
    "        \"\"\"\n",
    "        parts = filepath.split(\"/\", maxsplit=1)\n",
    "        if len(parts) > 1:\n",
    "            return parts[1]\n",
    "        else:\n",
    "            return parts[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_github_data():\n",
    "    allowed_extensions = {\"md\", \"mdx\"}\n",
    "\n",
    "    repo_owner = 'DataTalksClub'\n",
    "    repo_name = 'datatalksclub.github.io'\n",
    "\n",
    "    reader = GithubRepositoryDataReader(\n",
    "        repo_owner,\n",
    "        repo_name,\n",
    "        allowed_extensions=allowed_extensions,\n",
    "        filename_filter=lambda path: path.startswith(\"_podcast\")\n",
    "    )\n",
    "    \n",
    "    return reader.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "github_data = read_github_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RawRepositoryFile(filename='_podcast/s01e01-roles.md', content='---\\ntitle: \"Data Team Roles Explained\"\\nshort: \"Roles in a Data Team\"\\nguests: [alexeygrigorev]\\n\\nimage: images/podcast/s01e01-roles.jpg\\n\\nkeywords: \"data team roles, data scientist, data engineer, machine learning engineer, data analyst, MLOps engineer, product manager, data team structure, data science roles, ML engineer vs data engineer, data team responsibilities, data science career\"\\n\\nseason: 1\\nepisode: 1\\n\\nids:\\n  youtube: UukjwSIAnpw\\n  anchor: Roles-in-a-data-team---Alexey-Grigorev-emqcft\\n\\nlinks:\\n  youtube: https://www.youtube.com/watch?v=UukjwSIAnpw\\n  anchor: https://anchor.fm/datatalksclub/episodes/Roles-in-a-data-team---Alexey-Grigorev-emqcft\\n  spotify: TODO\\n  apple: TODO\\n---\\n\\nThe topic today is the roles in data teams. We want to understand what kind of people work in the data team, what responsibilities they have, what they do, and what they need to know.\\n\\n**Q: Before we dive into the different roles in data teams, could you tell us about your professional background and what perspective you bring to this topic?**\\n\\nI work as a **lead data scientist** and this means that my views might be a bit biased towards the views of a data scientist. This is how a data scientist sees other people, so I might not necessarily be right in all aspects. If you think I\\'m wrong somewhere, please tell me, because the views of how I see data engineers are simplified - I don\\'t see all the complexities of the work they\\'re doing.\\n\\n**Q: What are the main roles that typically exist within a data team, and how do they differ from each other?**\\n\\nIn a data team there are many different roles. First we have a **product manager** - somebody who is responsible for the entire product and for making sure that the team is building the right thing. Then we have data specialists. The product manager is a little less technical than the rest, but we have people such as **data analysts**, **data scientists**, **data engineers**, **machine learning engineers**, and **MLOps engineers**.\\n\\nIt\\'s often difficult to understand who is who and who needs to do what, and this is why we have this conversation today - to answer these questions. There are also more traditional roles such as **backend engineers**, **mobile engineers**, and **software engineers**. All these people often work together with data scientists and other people to create data science products.\\n\\n**Q: Let\\'s dive deeper into the specific responsibilities of each role. Could you walk us through a concrete example to illustrate how these roles work together?**\\n\\nI\\'ll use an example from my work. I work at OLX Group - OLX is a platform for online classifieds where you can sell things you don\\'t need. If you have an iPhone you want to sell, you go to this website, create a listing, and sell your iPhone. If you want to buy something, you go to OLX, browse different advertisements, find what you want, and buy it.\\n\\nImagine we want to automatically detect the category of an item. If I\\'m selling an iPhone and creating a listing, the system should understand that iPhone belongs in the mobile phones category. This is the problem we\\'ll use for illustration.\\n\\n**Q: Let\\'s start with the product manager role. What are the main responsibilities of a product manager in a data team, and how do they contribute to the project?**\\n\\nThe main responsibility of a product manager is to **make sure that the team is building the right thing** - that whatever we build will be used by the user. Often a team is solving some problem, but in the end these services are not used. This is a problem in many companies, and that\\'s why the role of a product manager exists - to make sure that the team is as close to the user as possible. The product manager **speaks on behalf of the user**.\\n\\nThe main skills here are **communication skills**. For a data scientist, communication is a soft skill, but for a product manager it\\'s a hard skill - something they must have to do their work. They also need to do **prioritization and planning** to tell others what is more important, what is less important, what the team should focus on and what they shouldn\\'t focus on.\\n\\nIn our example, somebody comes with a request: \"We want to build this feature to automatically categorize a listing.\" First, this person would go to a product manager. Product managers receive these kinds of requests - they act as a gateway to receive all these requests. Then the task of a product manager is to figure out: do users really need that? Is this feature really important? Is it an important problem to solve or not? They often work together with data analysts to understand if this problem is worth solving.\\n\\n**Q: What about data analysts? What are their specific responsibilities and how do they contribute to the data team\\'s success?**\\n\\nThe role of a data analyst is to **understand the data we have and explain this data to others**. Analysts know all the data that we have in our company. They know how to get this data and how to interpret results. They are in charge of **building different dashboards** and **defining KPIs** - showing profit, number of listings, how many contacts buyers made to sellers. Data analysts know how to capture these metrics and how to present them in a way that others will understand. They are also in charge of **building reports**, often to the executive team, with actionable recommendations.\\n\\nWhen it comes to skills, data analysts should know **SQL** - this is the main tool. They should know a programming language such as **Python** or **R**. They should also be comfortable using **Tableau** or similar tools for building dashboards. They should know basics of **statistics** to be able to do different experiments, and a bit of **machine learning** - to do regression analysis or time series prediction. If we want to predict how many listings there will be next week or next month, this is something that data analysts can also do.\\n\\nData analysts in this example would help quantify the extent of a problem for the product manager. If somebody comes with a problem - \"build a model for automatic categorization of listings\" - data analysts would help quantify the problem. How many users are affected by this? How many users cannot finish creating the listing because they cannot select the right category? Or how many listings don\\'t have the right category? Analysts fetch the data and say \"this problem is indeed a problem,\" and then together with product managers they can say \"this problem is worth solving,\" and the team will go ahead and start solving this problem.\\n\\nData analysts also do this: after we develop the feature and have a model that categorizes the listings, we want to understand if this service is actually effective, if this model really helps people and solves the problem. We typically **run an experiment such as an A/B test**. We check whether fewer users drop from the posting flow, so more users successfully finish posting an item for selling, or there are fewer ads that end up in the wrong category. We run an experiment and then the task of a data analyst is to **quantify and understand if this model indeed helps** compared to not using a model.\\n\\n**Q: How do data scientists differ from data analysts? What are their unique responsibilities and skill sets?**\\n\\nData scientists and data analysts have pretty similar roles, and in some companies it\\'s actually the same person doing both jobs. But typically, data scientists **focus more on predicting rather than explaining**. A data analyst fetches the data, looks at it, explains what is going on, and gives recommendations. But the task of a data scientist is focused more on predicting - how we can use this data to build a machine learning model for prediction. They\\'re using the data, **incorporating the data in the product**. The focus is **more on engineering than analysis**. That\\'s the main difference in my opinion between a data scientist and a data analyst. Data scientists are more like engineers, and they work closely with integrating data solutions in the product that users use.\\n\\nThe skills for data scientists are, of course, **machine learning** - this is the main tool they use for building these predictive services. Then **Python** as a programming language, and **SQL** to fetch the data and train the model. They also need **Flask** and **Docker** to create a web service for serving this model. In our example, when we want to predict the category of an item, data scientists are the people who **develop the model** for predicting this category. Once they have a model, they **develop a web service** for hosting it.\\n\\n**Q: What about data engineers? What are their key responsibilities and how do they support the rest of the data team?**\\n\\nData engineers do all the **heavy lifting when it comes to data**. For data scientists and data analysts to be able to use this data, a lot of work needs to happen to make it possible for data analysts to go to a database, fetch the data, do the analysis, and come up with a report. This is the focus of data engineers - to make sure that this is possible. That all the data needed appears in a consumable form and doesn\\'t affect the main product. This is usually called **creating a data lake** - all the data that users generate is captured properly and saved in a separate database so that analysts can run the analysis and data scientists can use this data for training models. They make it possible to **run analytical queries** on the data that users generate.\\n\\nAlso, especially at larger companies, they need to make sure that **only people who are supposed to look at the data can actually access it**. People who are just snooping around and trying to look at personal data cannot do this unless they have a business reason - for example, to look at emails or mobile phones. They need to build a system that doesn\\'t let people access all the data without authorization.\\n\\nSkills here for data engineers - usually, for most companies I saw in Germany and Europe, data engineers need to know a cloud provider such as **AWS** (the most popular), or **Google Cloud**. They also need to know infrastructure tools such as **Kubernetes** and **Terraform**. Then data services such as **Kafka** or **RabbitMQ** - these are for capturing the data, processing the data, and saving it somewhere. Of course **databases** - this is where the data is saved so it\\'s accessible for data analysts. And data orchestration tools such as **Airflow** - they need to know how to use them to build complex data pipelines.\\n\\nIn the task that we have - creating a service for predicting the right category for a listing - data engineers make sure that all the data we need is there. First for doing the analysis, for quantifying the problem. And then the data about the listings themselves - everything we want to use for predicting the category. So this is their main responsibility.\\n\\n**Q: Are there other types of engineers that work in data teams beyond data engineers? What roles do they play?**\\n\\nYes, we have **machine learning engineers**. A machine learning engineer is somebody who takes whatever data scientists built and their task is to **scale that**. Data scientists build a service and machine learning engineers pick up this service and make sure the service is **scalable**, **maintainable**, and follows the **best engineering practices**.\\n\\nThe focus here is **more on engineering than on modeling**. When I say taking what data scientists built, I don\\'t mean that data scientists finish their work, hand over the model, and say \"take it and do something with this.\" Rather, they work **together with data scientists side by side**, making sure that the services that data scientists develop are scalable, maintainable, and follow best engineering practices.\\n\\nSkills here are similar to data engineers. They also need to use the **cloud**, infrastructure tools such as **Kubernetes** and **Terraform**, **Python**, and other programming languages. They also work often closely with traditional engineers such as backend engineers, frontend engineers, or mobile engineers to make sure that these models are included in the final product that users use.\\n\\nIn our example of predicting the category, machine learning engineers ideally work together with data scientists on making sure that this model can be **productionized**. Once it\\'s rolled out to the users, it\\'s stable, it will sustain the load, and it\\'s maintainable and possible to make changes in the future when needed.\\n\\n**Q: What about DevOps engineers and Site Reliability Engineers? How do they fit into data teams and what are their responsibilities?**\\n\\nAnother kind of engineers are also important in a data team - **DevOps engineers** or sometimes **Site Reliability Engineers (SREs)**. They are also similar to machine learning engineers, but they focus more on **availability and reliability of the services**. They are not strictly working with data only - this is more of a general role. They focus more on **infrastructure than business logic** - things such as networking, provisioning, all the infrastructure, all the servers where our services are running.\\n\\nThey take care of **collecting all the operational metrics** such as CPU usage, how many requests per second our services process. They often **set up alerts**, they have **on-call** responsibilities. They really focus on making sure that the services are **up and running all the time without any breaks**.\\n\\nIf something breaks, SREs can quickly **diagnose the problem and fix it**, or involve an engineer to help them.\\n\\nSkills here are again pretty similar to ML engineers. They need to know **cloud**, infrastructure tools, a programming language such as **Python**, but they also need to be **Unix/Linux experts** and they need to know **networking**. They should also know and follow all the **best DevOps practices** such as automation, **CI/CD**. Of course, ML engineers and data engineers should also know that, but DevOps engineers and Site Reliability Engineers focus on making sure that these practices are followed and they come up with tools to make sure that it\\'s happening.\\n\\n**Q: What about MLOps engineers? How do they differ from traditional DevOps engineers, and what makes their role unique in data teams?**\\n\\nMaybe you heard about **MLOps engineers** - this is a pretty recent trend to have MLOps, not just DevOps. In my opinion, and many people disagree, but in my personal opinion, an MLOps engineer is a **DevOps engineer who knows the basics of machine learning**. They know some machine learning concepts - they know what a model is, they know that it\\'s not deterministic, sometimes the output is a probability. They know the **life cycle of a machine learning model** - there is a training phase, there is a serving phase. But still, the background is more **operational support** than anything else.\\n\\nThey still know and follow all these DevOps practices, they make sure that everybody is following them, they set up all this **continuous integration**, **continuous delivery pipelines**. Their responsibility is to make sure that the services we develop - data scientists, machine learning engineers, data engineers - **are up and running all the time**.\\n\\n**Q: Could you provide a summary of all these different roles and their key responsibilities in a data team?**\\n\\nLet me summarize:\\n\\n- **Product managers** make sure that the team is building the right thing. They act as a gateway to all the requests and are close to the user.\\n- **Data analysts** understand and analyze data. They interpret the results, build dashboards and reports.\\n- **Data scientists** build the models and incorporate these models in the product.\\n- **Data engineers** prepare all the data for analysts and data scientists to make their life easier.\\n- **Machine learning engineers** help data scientists scale the machine learning services and establish best engineering practices.\\n- **DevOps engineers and Site Reliability Engineers** focus on availability, reliability, and best DevOps practices - making sure that the service is up and running all the time, and if something breaks, they can quickly fix it, even if it\\'s at night or over the weekend.\\n\\n**Q: How can data engineers best support the other members of the data team? What does effective collaboration look like?**\\n\\nI think I mostly answered that question during the description of the roles, but to be a bit more concrete - the best way that engineers can support others, support data analysts and data scientists and all the rest, is to **work together in one team, work on the same problem**.\\n\\nEven though the focus is different, when you work on the same problem - if we work on building a service that predicts and identifies the category of a listing correctly - we want to work together as one team. Then data engineers will make sure that **all the needed data** - the data we need for analysis, the data we need for training the model - **is there**. If it\\'s not, they usually take care of making sure that this data is available.\\n\\n**Q: Are there different ways that machine learning models can be deployed in production? What are the main deployment patterns?**\\n\\nI described a case when a model is running online - a data scientist develops a model, they put this inside a web service, and then machine learning engineers help them to make sure this is scalable. But sometimes we have models that we don\\'t necessarily use in this way. Sometimes we just want to predict something once per hour or once per day. For these cases we don\\'t need a web service.\\n\\nOne example could be: we have many users on our platform and we want to identify users who would be interested in particular listings. Basically, we want to advertise something to them. From all the users we have, we want to find users who are most likely to react positively to this kind of advertising.\\n\\nUsually we don\\'t need to do this in real time - it\\'s fine if we do it once per day. Once per day we run our model, score all our users, and see that for this kind of ads these users are more likely to be interested. Then we just send emails to these users saying \"hey, you might be interested in seeing this.\"\\n\\nIn this case we don\\'t serve the models online, we do it offline. We call it **batch serving** because we do this periodically. The job of data engineers here would be to help data scientists make sure that it\\'s possible to execute the model in such a way that it runs periodically, every day. The job of a data engineer would be to **help data scientists get the data into the model**, then the model does some prediction, and they will also **help get the predictions out of the model and save them** in such a way that this data can later be used by other services.\\n\\n**Q: What\\'s the key difference between machine learning engineers and data engineers when it comes to scaling data science models? How do their responsibilities overlap or differ?**\\n\\nI think I partly answered that. In my personal opinion, this is at least the trends I see around me in the companies where I worked or in other companies - machine learning engineers mostly work on **online things**. The line is blurry, but the main difference in my opinion is that machine learning engineers focus more on online things. If we have a model and we want to serve it online so it can be used from a product, then this is what the machine learning engineer would do. If this is something we want to do offline, executed once per day, this is something that the data engineer would do.\\n\\nBut again, data engineers are also involved in things such as setting up Kafka, and Kafka is of course more real-time than offline. You can argue here that it\\'s not really clear what is the difference, and yeah, in some cases there is no difference - actually both roles are doing the same job.\\n\\nBut one thing you can use to separate the two, in my opinion: a data engineer is **somebody who helps to prepare the data** - so it\\'s **before the job of a data scientist**. And a machine learning engineer is somebody who is **picking up the model and doing the job after**.\\n\\nBut again, it\\'s not like a wall and then a data scientist just throws a model over this wall. Of course they work together. Data engineers work together with data scientists to develop a model, and then data scientists work together with machine learning engineers to serve the model. This is just my opinion and I think opinions differ on this question. In some companies there is not really a difference.\\n\\n**Q: Should data teams also include business analysts who sit between product managers and the technical data team? What value do they bring?**\\n\\nYeah, definitely, I think it\\'s a really good idea. A business analyst - or what they called an analyst - of course, sometimes the roles are different. We have product analysts, we have data analysts, we have business analysts. Sometimes it\\'s a different role, sometimes it\\'s the same role, so it\\'s difficult to draw a line here.\\n\\nBut I think they are pretty similar in this sense that they **help the product manager to quantify the size of a problem** and understand if this problem is actually worth solving. In some teams I know there is even no product manager - there is just a business analyst who **translates the requirements of a user to the team**. So it\\'s also possible.\\n\\n**Q: What communication and soft skills are most important for the different roles in a data team? How do these skills vary by position?**\\n\\nI think the main soft skill is **communication skill** - basically being able to talk to each other and understand each other. When we work, everyone works in a team. Product managers are less technical, data engineers and machine learning engineers are more technical, and Site Reliability Engineers are even more technical, having more hardcore skills in Unix and networking.\\n\\nBasically, **everyone in this team should be able to speak in the same language**. When a data scientist says something about machine learning, they need to make sure that everyone on the team understands what they are saying. Instead of going deep into saying \"the gradient is exploding here\" and no one understands what they talk about, they of course have to work with others and really explain what the problem is, how to address the problem, using metaphors or things like that.\\n\\nFor analysts, I think, probably for all the positions, **writing documentation is important**. Of course, documentation is different. For machine learning engineers or other engineers, when they write documentation, this is usually intended for other engineers. For analysts, they need to be probably better at writing in the sense that they really need to know **how to write in such a way that management understands** - the executive team understands what is the problem and what is the solution they are proposing when they are writing different reports about different things.\\n\\nThe more a person talks to the business side of things, to the user, the more they need to have a slightly different set of communication skills. But again, I think the most important thing is that **everyone in the team understands each other**.\\n\\n**Q: How do the roles in a data team change based on team size? For example, would you typically see a machine learning engineer in a small startup team, or do they usually come in later as the company grows?**\\n\\nYeah, it really depends on the company. I think there was a trend a while ago - I\\'m not sure it still exists - but many people thought that they can just hire a data scientist and this data scientist would solve all the problems that the company has. Of course, that wasn\\'t true because then they realized: okay, we probably need a data engineer, we probably need a machine learning engineer, we probably need a data analyst.\\n\\nOf course, if it\\'s just starting and it\\'s a small company, a small team, having a **data engineer who knows a bit of machine learning is probably enough**. Or it can be a **machine learning engineer who knows how to set up the data pipelines** and things like that. Ideally, it should be **somebody who knows how to do things end-to-end**. A machine learning engineer could be that person - if that person knows how to set up a data pipeline, how to train a model, and how to serve it, then this person is an ideal candidate for a small team.\\n\\nThen, of course, when the project becomes bigger, the team grows, and there are people who **specialize more in certain areas**. Of course, then it makes sense to add more people. But I don\\'t think there is a right or wrong answer - it just depends on what the company wants to achieve and what kind of person this machine learning engineer is.\\n\\nJust thinking out loud - maybe in some cases it actually makes sense to **hire a machine learning engineer as the first person in a team**. Because they are engineers, they know how to build things. It wouldn\\'t be a problem for them to figure out how to build a data pipeline, it wouldn\\'t be a problem for them to figure out how to serve a model. And since they are machine learning engineers, they know a bit of machine learning to train a simple model such as logistic regression or a decision tree and already start solving a business problem and **start bringing value to the company**. Then once this person can show the value in this product, in this service, then the team can start growing and add more people such as data engineers and data scientists.\\n\\n**Q: Do data engineers primarily work with big data, or do they also handle smaller datasets? What determines when you need dedicated data engineering resources?**\\n\\nYeah, I think if the data is small - again, there is probably a question like how large data should be to call it **big data** - but let\\'s say a few million events per day, or maybe even 100 million events per day, that would qualify as big data. Then, of course, you need to have a **dedicated person who is dedicated to just processing this data** because there is a lot of volume. It will not be possible for a data scientist to take care of everything, and then in this case we need a data engineer who will work on making sure that the data can be processed, the data is stored in the right format, and others can access this data.\\n\\nBut if it\\'s a small company and there\\'s not so much load - it\\'s not a company that works with advertisement and they don\\'t generate a lot of events per day - then potentially even a **data scientist who does not necessarily have a very strong engineering background can already develop a first prototype**.\\n\\n**Q: Is there a clear distinction between full-stack machine learning developers and full-stack web developers? How do these roles differ in practice?**\\n\\nJust to make sure I understood the question - the question is asking if we have different kinds of full-stack engineers. We have machine learning full-stack engineers, or full-stack data scientists who can do things end-to-end. And then we have web engineers, full-stack engineers who can do things there end-to-end.\\n\\nI think we actually need the separation here because, in my opinion, when we are talking about a **full-stack engineer**, this is somebody who mostly focuses on **web**. We quickly want to create an application that users can use, such as a web application, and this is what they would do. The nature of work here is a bit different from data science, so the process is a bit different.\\n\\nI think fundamentally the processes are similar, but there are some differences as well. In the case of **full-stack data scientists**, they need to focus more on **data science and backend**. In my opinion, **full-stack web developers** focus more on **frontend and a bit of backend**. I think there is not a lot of connection between these two.\\n\\nBut I might be wrong, and I can imagine that some companies, especially early-stage startups, where **one person can do everything** - starting from setting up a company\\'s website to collecting the data to training the model, and then maybe even configuring Wi-Fi routers in the office. I can imagine that this can also happen. But as the company grows, there is **more and more separation**, and of course, at the end, when the company is big, we have all these different roles which we talked about today.\\n\\n**Q: In smaller teams that don\\'t have dedicated MLOps or DevOps engineers, who would typically handle these operational tasks? What\\'s the fallback approach?**\\n\\nIn my opinion, it would be just an engineer. Let\\'s say if a company already has a **backend engineer** - it could be that backend engineer. It should be possible to train that person, to explain the basics of machine learning, and they will be able to perform this job. Or, of course, at some point the company will need to hire that person or grow somebody internally into this role.\\n\\nI guess we are wrapping up for today. Thank you very much for attending the session today, and looking forward to seeing you next week.\\n\\nTalk to you soon. Goodbye!')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(github_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "title: \"Making Sense of Data Engineering Acronyms and Buzzwords\"\n",
      "short: \"Making Sense of Data Engineering Acronyms and Buzzwords\"\n",
      "guests: [nataliekwong]\n",
      "\n",
      "image: images/podcast/s05e02-data-engineering-acronyms.jpg\n",
      "\n",
      "season: 5\n",
      "episode: 2\n",
      "\n",
      "ids:\n",
      "  youtube: t9Z1S3OYnJU\n",
      "  anchor: Making-Sense-of-Data-Engineering-Acronyms-and-Buzzwords---Natalie-Kwong-e177303\n",
      "\n",
      "links:\n",
      "  youtube: https://www.youtube.com/watch?v=t9Z1S3OYnJU\n",
      "  anchor: https://anchor.fm/datatalksclub/episodes/Making-Sense-of-Data-Engineering-Acronyms-and-Buzzwords---Natalie-Kwong-e177303\n",
      "  spotify: https://open.spotify.com/episode/1AvtwdcAXGGjdJ7fl0Hsuw\n",
      "  apple: https://podcasts.apple.com/us/podcast/making-sense-of-data-engineering-acronyms-and/id1541710331?i=1000534990760\n",
      "\n",
      "transcript:\n",
      "- line: This week we'll try to make sense of common engineering acronyms and buzzwords\n",
      "    with the help of our special guest today, Natalie. Natalie works at Airbyte, focusing\n",
      "    on building user experience and overseeing analytics. Your expertise includes\n",
      "    scaling analytics teams and systems from the ground up. Welcome, Natalie.\n",
      "  sec: 94\n",
      "  time: '1:34'\n",
      "  who: Alexey\n",
      "- line: Thank you. Happy to be here.\n",
      "  sec: 116\n",
      "  time: '1:56'\n",
      "  who: Natalie\n",
      "- header: \"Natalie\\u2019s background\"\n",
      "- line: Before we go into our main topic of understanding these acronyms and buzzwords,\n",
      "    let's start with your background. Can you tell us about your career journey so\n",
      "    far?\n",
      "  sec: 118\n",
      "  time: '1:58'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, sure. I've been in startup tech for my entire career. I actually started\\\n",
      "    \\ out in the Bay Area at Vox, doing marketing operations. Then I moved into marketing\\\n",
      "    \\ analytics at a company called Admiral. I really went deeper into analytics there,\\\n",
      "    \\ doing R, SQL, a little bit of Python, and really ended up becoming an acquisition\\\n",
      "    \\ analyst. This involves looking at both marketing and sales and how they interact\\\n",
      "    \\ \\u2013 so that would be building out multi-touch attribution models and things\\\n",
      "    \\ like that.\"\n",
      "  sec: 128\n",
      "  time: '2:08'\n",
      "  who: Natalie\n",
      "- line: \"After that, I moved a little bit more into operations at AppDynamics, which\\\n",
      "    \\ has been acquired by Cisco, and then moved to actually manage my own team at\\\n",
      "    \\ a company called Keep Truckin\\u2019, which is focused on more on the IoT space,\\\n",
      "    \\ filling out dashcams and ELDs for the trucking industry. There, I built out\\\n",
      "    \\ a team of about 11 analysts, already from marketing and sales to customer success\\\n",
      "    \\ and product. Then I moved on to Harness doing a customer sales ops role. So\\\n",
      "    \\ I really kind of straddled that analytics and operation space. Now I'm in Airbyte,\\\n",
      "    \\ doing growth and analytics.\"\n",
      "  who: Natalie\n",
      "- header: Airbyte\n",
      "- line: What does Airbyte do?\n",
      "  sec: 199\n",
      "  time: '3:19'\n",
      "  who: Alexey\n",
      "- line: \"Airbyte is an extract/load or \\u201CELT\\u201D platform \\u2013 with Transform\\\n",
      "    \\ being the T \\u2013 that essentially allows you to ingest a lot of different\\\n",
      "    \\ data from different sources, maybe APIs like AdWords or Facebook ads, weave\\\n",
      "    \\ it in data warehouses like Snowflake, and bring them into your data warehouse.\"\n",
      "  sec: 202\n",
      "  time: '3:22'\n",
      "  who: Natalie\n",
      "- header: What is ETL?\n",
      "- line: \"You mentioned a few things \\u2013 transform, ingest, and ELT. We wanted to\\\n",
      "    \\ talk about this today. Actually, this is a question I get sometimes. Not super\\\n",
      "    \\ often, but it pops up: \\u201CWhat's the difference between ELT/ETL, all these\\\n",
      "    \\ acronyms \\u2013 what do they actually mean?\\u201D That's why we\\u2019re having\\\n",
      "    \\ a conversation today \\u2013 to finally figure that out and help everyone else\\\n",
      "    \\ with that. Let's start with ETL, which is probably the oldest concept from data\\\n",
      "    \\ engineering. I think it was used even before the term \\u2018data engineering\\u2019\\\n",
      "    \\ even existed. I think it's pretty old, coming from business intelligence times\\\n",
      "    \\ or even older. I don't know. So what is ETL?\"\n",
      "  sec: 226\n",
      "  time: '3:46'\n",
      "  who: Alexey\n",
      "- line: \"ETL stands for \\u2013 E is the extract, T is the transform, and L is the\\\n",
      "    \\ load. When we think about ETL, we're really thinking about extracting the source-specific\\\n",
      "    \\ routines where you pull selected data out of an external system. The transform\\\n",
      "    \\ layer is kind of your specific business logic. Your organization is going to\\\n",
      "    \\ have some sort of logic that really defines how you pull the data or certain\\\n",
      "    \\ use cases that you have that are operational. Then the loading piece is where\\\n",
      "    \\ you have destination-specific routines to push data into the place where it's\\\n",
      "    \\ going to be consumed. So that's kind of the traditional way to think about it.\"\n",
      "  sec: 270\n",
      "  time: '4:30'\n",
      "  who: Natalie\n",
      "- line: \"Can you think of an example? Let's say there are some sources, right? We\\\n",
      "    \\ extract data from these sources, transform the data somehow, and then put it\\\n",
      "    \\ in a data warehouse. Can you think of an example for this \\u2013 you mentioned\\\n",
      "    \\ something like Facebook ads or something like this?\"\n",
      "  sec: 313\n",
      "  time: '5:13'\n",
      "  who: Alexey\n",
      "- line: \"Generally, you might see \\u2013 if you're working in the marketing space,\\\n",
      "    \\ for example \\u2013 your data is stored in Google AdWords, because you're running\\\n",
      "    \\ data or you're running ads on Google. Or maybe the same thing but with Facebook.\\\n",
      "    \\ If you're working in sales, your data might be stored in Salesforce, your CRM.\\\n",
      "    \\ If you're working in finance, it might be stored in NetSuite, maybe. So all\\\n",
      "    \\ of these different kinds of API sources all house some data that your business\\\n",
      "    \\ needs to build some picture of how the business is doing. Those sources would\\\n",
      "    \\ be the places that we would extract from.\"\n",
      "  sec: 332\n",
      "  time: '5:32'\n",
      "  who: Natalie\n",
      "- line: The example is that your background is more in marketing, as I understood.\n",
      "    You would want to extract some things from Google AdWords and from Facebook, right?\n",
      "    There is something interesting in this data that you want, and then you do some\n",
      "    transformation on it. You go to Google AdWords, it returns you some data, and\n",
      "    then you want to transform this data. Is that right?\n",
      "  sec: 369\n",
      "  time: '6:09'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, exactly. One really good use case that we could speak to here \\u2013\\\n",
      "    \\ just to be a little bit more concrete \\u2013\\u201CWhat is your cost to acquire\\\n",
      "    \\ a customer?\\u201D You need an accurate CAC, in other words. In order to get\\\n",
      "    \\ that, you need to know how many customers that you've specifically acquired\\\n",
      "    \\ from, let's say, Google AdWords. You also need to know how much is being spent\\\n",
      "    \\ to acquire those customers. The only way to really concretely bridge those things\\\n",
      "    \\ is to pull out data from your CRM, which stores all of your revenue information\\\n",
      "    \\ and where the customers came from. Then you also pull up the spend data from\\\n",
      "    \\ a more upper-funnel source. Then you merge those together using the transform\\\n",
      "    \\ capability.\"\n",
      "  sec: 397\n",
      "  time: '6:37'\n",
      "  who: Natalie\n",
      "- line: And then everything eventually goes to the data warehouse, which you use for\n",
      "    building reports. Then you see how much money was spent? Is that right?\n",
      "  sec: 438\n",
      "  time: '7:18'\n",
      "  who: Alexey\n",
      "- line: \"Exactly. Yep. The way that you finish out the process is \\u2013 once it's\\\n",
      "    \\ loaded in the data warehouse, in this traditional ETL model, you'd essentially\\\n",
      "    \\ have a data mart that specifically says, \\u201CHey, this is the data mart that\\\n",
      "    \\ answers that question.\\u201D Then you would have a visualization tool like Looker\\\n",
      "    \\ or Superset in order to show that from a visualization perspective \\u2013 bring\\\n",
      "    \\ it out to the business so that they can actually consume the insights.\"\n",
      "  sec: 447\n",
      "  time: '7:27'\n",
      "  who: Natalie\n",
      "- header: Why ELT instead of ETL?\n",
      "- line: What is ELT, then? Why do we want to switch to this tool?\n",
      "  sec: 477\n",
      "  time: '7:57'\n",
      "  who: Alexey\n",
      "- line: \"I think the traditional way to think about this is \\u2013 ETL is just a little\\\n",
      "    \\ bit more inflexible. The business logic changes a lot of the time and you're\\\n",
      "    \\ going to receive friction whenever you need to change part of this pipeline.\\\n",
      "    \\ So because you're transforming it before you load it into a data warehouse,\\\n",
      "    \\ it's difficult to actually bring in new data. Let's say, there's a new table\\\n",
      "    \\ or a new field that gets added to Salesforce, the new data that you're collecting\\\n",
      "    \\ or the new data source, it's fairly inflexible to just go ahead and add those\\\n",
      "    \\ things. It often will force data to be completely re-extracted, which takes\\\n",
      "    \\ much more computation and much more time than is really necessary for small\\\n",
      "    \\ changes like this.\"\n",
      "  sec: 483\n",
      "  time: '8:03'\n",
      "  who: Natalie\n",
      "- line: \"You also have this lack of autonomy. What we've generally seen is that these\\\n",
      "    \\ ELT tools are actually managed by engineering teams. When analysts \\u2013 who\\\n",
      "    \\ are working more with the business end \\u2013 have these needs, they actually\\\n",
      "    \\ have a dependency on an external team to go and compute those. This, of course,\\\n",
      "    \\ creates more cycles and takes more time to make these changes. Really the crux\\\n",
      "    \\ of it is \\u2013 it requires engineering to be actually involved.\"\n",
      "  who: Natalie\n",
      "- line: So ELT is really generalizing to the ETL. Instead of having the transform\n",
      "    be in the middle, in ELT, the T is at the end. Thus, instead of having a tool\n",
      "    to actually manage the transformation for you, you're actually bifurcating the\n",
      "    E-L and the T. Everything is loaded into your data warehouse and then the transformation\n",
      "    happens after the data is loaded. The transformation actually happens within the\n",
      "    data warehouse itself, the destination.\n",
      "  who: Natalie\n",
      "- header: Transformations\n",
      "- line: \"Yeah, thanks. We already have a comment about transformations. The question\\\n",
      "    \\ is, \\u201CWhen you say transform, can you elaborate so that we can understand\\\n",
      "    \\ what\\u2019s happening here?\\u201D Like, \\u201CWhat kind of transformations do\\\n",
      "    \\ we run?\\u201D\"\n",
      "  sec: 600\n",
      "  time: '10:00'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, we definitely can be more specific about that. It can go from the very\\\n",
      "    \\ basic \\u2013 the simplest transformation I can think of is something like changing\\\n",
      "    \\ a column type from a numeric to a character one. That's a very basic transformation.\\\n",
      "    \\ It's almost like it's a casting of a column to a different data type. The more\\\n",
      "    \\ complex transformations generally will join across different data sources. So\\\n",
      "    \\ you'll say \\u201CI want to grab AdWords data and Salesforce data, join them\\\n",
      "    \\ using some kind of unique identifier, and then figure out how to show these\\\n",
      "    \\ data sources alongside each other in some sort of finalized data model.\\u201D\\\n",
      "    \\ Generally, we think of these as a kind of transformations that you're running\\\n",
      "    \\ in SQL. These can be very simple SQL statements or pretty complex ones. But\\\n",
      "    \\ those are the two ways that I see transformation being done.\"\n",
      "  sec: 622\n",
      "  time: '10:22'\n",
      "  who: Natalie\n",
      "- line: \"When you swap the T and L, so that the T comes at the end, you said the reason\\\n",
      "    \\ for this is \\u2013 when T is in the middle (ETL) it's not flexible because the\\\n",
      "    \\ business logic can change. Then you also depend on engineering teams. I also\\\n",
      "    \\ imagine that, let's say the data we extract from the source, we don't need the\\\n",
      "    \\ entire response from the ads \\u2013 if we\\u2019re talking about marketing. So\\\n",
      "    \\ this service gives us some response. Let's say we keep only one part of this\\\n",
      "    \\ response, if we're interested in how much money we spent, for example.\"\n",
      "  sec: 679\n",
      "  time: '11:19'\n",
      "  who: Alexey\n",
      "- line: \"So we keep only this data, we transform it, and we load it to our data warehouse,\\\n",
      "    \\ only the specific part. Later somebody comes and says, \\u201CHey, what about\\\n",
      "    \\ some other thing from Google AdWords?\\u201D and you reply \\u201COkay, sorry,\\\n",
      "    \\ because our T was only keeping this part and we don't have the rest of the data.\\u201D\\\n",
      "    \\ Thus, by keeping the entire thing and then doing the transformation later, if\\\n",
      "    \\ somebody comes to us and asks for something extra, then the data is there. We\\\n",
      "    \\ just write another transformation on top of the data that we already extracted.\\\n",
      "    \\ Is that right?\"\n",
      "  who: Alexey\n",
      "- line: Exactly. Yep.\n",
      "  sec: 757\n",
      "  time: '12:37'\n",
      "  who: Natalie\n",
      "- header: How does ELT help analysts be more independent?\n",
      "- line: \"Yeah, and this part about depending on engineering teams \\u2013 I'm curious.\\\n",
      "    \\ How does it help analysts to be more independent now? Why do they not depend\\\n",
      "    \\ on engineers now?\"\n",
      "  sec: 759\n",
      "  time: '12:39'\n",
      "  who: Alexey\n",
      "- line: \"Generally, analytics teams operate within the data warehouse itself. I know\\\n",
      "    \\ you recently had an interview with Victoria, an analytics engineer. There's\\\n",
      "    \\ sort of a rise of this analytics engineer role, which is a role that is generally\\\n",
      "    \\ found on the analytics team. Essentially, it\\u2019s managing the process from\\\n",
      "    \\ the pipelines to the data warehouse and building out that transformation later.\\\n",
      "    \\ Instead of business analysts or product analysts going to the engineering team,\\\n",
      "    \\ which are generally more focused on the data platform or data infrastructure,\\\n",
      "    \\ we can actually see this rise of the analytics engineer role. This role allows\\\n",
      "    \\ there to be autonomy within the analytics team itself. That allows them to not\\\n",
      "    \\ only understand the business, its needs, and impact, but also to be able to\\\n",
      "    \\ make their changes very quickly.\"\n",
      "  sec: 772\n",
      "  time: '12:52'\n",
      "  who: Natalie\n",
      "- line: Basically, analysts were not necessarily strong engineers, so we have an analytic\n",
      "    engineer role that can help them if something is more complex than just writing\n",
      "    the usual SQL query, right?\n",
      "  sec: 825\n",
      "  time: '13:45'\n",
      "  who: Alexey\n",
      "- line: \"Yeah. I think a lot of these transformations can honestly be done using SQL.\\\n",
      "    \\ That's just very ubiquitous \\u2013 it's a very well understood, very common\\\n",
      "    \\ language. The level of access or the level of ability to access it and build\\\n",
      "    \\ your own transformations \\u2013 that barrier is much lower. Even if the team\\\n",
      "    \\ is so small that you don't have an analytics engineer, you're essentially empowering\\\n",
      "    \\ your analysts to be much more full-stack and say, \\u201CI know that the data\\\n",
      "    \\ is in the data warehouse, all I have to do is write SQL using something like\\\n",
      "    \\ DBT. Then I can service any requests or generate any insights autonomously.\\\n",
      "    \\ That reduces my time to be able to make positive relationships with my stakeholders.\\u201D\"\n",
      "  sec: 840\n",
      "  time: '14:00'\n",
      "  who: Natalie\n",
      "- line: Also, if the data is already extracted, I guess you have fewer steps to run.\n",
      "  sec: 894\n",
      "  time: '14:54'\n",
      "  who: Alexey\n",
      "- line: Yeah. Honestly, a big part of it is also speed. Because it's already there\n",
      "    and because these data warehouses have really scaled out how much time it takes\n",
      "    to compute. The cost of storage is also way down and has produced a ton over time.\n",
      "    The amount of speed it takes to actually even do these computing calculations\n",
      "    is much lower.\n",
      "  sec: 903\n",
      "  time: '15:03'\n",
      "  who: Natalie\n",
      "- header: Data marts and Data warehouses\n",
      "- line: \"You also mentioned one thing when talking about ETL \\u2013 this thing called\\\n",
      "    \\ data mart. We also talked about the data warehouse. What are those? What is\\\n",
      "    \\ a data mart? What is a data warehouse? What is the difference between them?\"\n",
      "  sec: 930\n",
      "  time: '15:30'\n",
      "  who: Alexey\n",
      "- line: \"=Data marts are very specific. Maybe we can use marketing again as a use\\\n",
      "    \\ case. In this case, you could say \\u201CI'm going to build a data mart to serve\\\n",
      "    \\ a dashboard that I'm going to build in Superset or Looker.\\u201D That data mart\\\n",
      "    \\ specifically contains the average spend \\u2013 the Facebook spending \\u2013\\\n",
      "    \\ aggregates. You put them together, build out how many leads came in from those\\\n",
      "    \\ sources, how many customers actually converted from those sources, and actually\\\n",
      "    \\ serve a marketing use case. On the same level, you can produce data marts for\\\n",
      "    \\ sales, finance, or product. But they each serve a certain use case for the business.\"\n",
      "  sec: 945\n",
      "  time: '15:45'\n",
      "  who: \"I think of data warehouses sort of as places to store data marts. When I think\\\n",
      "    \\ about data warehouses, there's an ingestion layer. Some users of ours, they'll\\\n",
      "    \\ call it an ingestion DB. Maybe within your data warehouse, you have multiple\\\n",
      "    \\ databases. That first layer is almost like the rawest form that comes from Airbyte.\\\n",
      "    \\ You hook your data warehouse up to, let's say, Snowflake, and you have a database\\\n",
      "    \\ called \\u201Cingestion DB\\u201D. That's essentially it \\u2013 you don't touch\\\n",
      "    \\ it \\u2013 but that is where your next layer comes from. This could be maybe\\\n",
      "    \\ a common layer, which is something that maybe several teams can draw from in\\\n",
      "    \\ order to build out the data marts.\"\n",
      "- line: So a data mart is basically a bunch of tables within a database, right? If\n",
      "    I understood that correctly.\n",
      "  sec: 1039\n",
      "  time: '17:19'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, it\\u2019s post-transformation. I think you can have a lot of different\\\n",
      "    \\ types of data tables. But the ones that I would consider a data mart is like\\\n",
      "    \\ a finalized table \\u2013 it's almost production-ready. A business user can take\\\n",
      "    \\ this and there are enough guardrails in place so that when they do pull metrics\\\n",
      "    \\ out of it, they're sanitized. They're ready to use and the business user can\\\n",
      "    \\ trust the data that comes out of there.\"\n",
      "  sec: 1045\n",
      "  time: '17:25'\n",
      "  who: Natalie\n",
      "- header: Ingestion DB\n",
      "- line: \"So ingestion databases are everything that comes before data marts, right?\\\n",
      "    \\ This is where the data that is maybe dirty or not cleaned or that is not aggregated\\\n",
      "    \\ \\u2013 this is not something that business users can use. Right?\"\n",
      "  sec: 1075\n",
      "  time: '17:55'\n",
      "  who: Alexey\n",
      "- line: \"Exactly. It's the rawest form. We generally wouldn't want business users\\\n",
      "    \\ to be pulling off the raw forms of data, because they'll probably have to do\\\n",
      "    \\ some transformation. That transformation might not be consistent across different\\\n",
      "    \\ users in the business. So in order to reduce the potential mistakes or different\\\n",
      "    \\ interpretations of the data down the line, that's why that transformation layer\\\n",
      "    \\ exists \\u2013 to separate and bifurcate the ingestion from the actual business\\\n",
      "    \\ users and the data marts that they use.\"\n",
      "  sec: 1091\n",
      "  time: '18:11'\n",
      "  who: Natalie\n",
      "- header: ETL vs ELT\n",
      "- line: \"So previously, in ETL, we would extract some data, we would immediately do\\\n",
      "    \\ the transformation, apply it perhaps without saving it, and then put it into\\\n",
      "    \\ a data warehouse or data mart. Now the data that we extract, we first put it\\\n",
      "    \\ to the ingestion database, where we keep it, and then we run transformation\\\n",
      "    \\ on top of this. Then we pull it again to create some tables that we call data\\\n",
      "    \\ marts. This is where the data that is used by the final users \\u2013 the business\\\n",
      "    \\ users \\u2013 is where we keep it. Is that right?\"\n",
      "  sec: 1127\n",
      "  time: '18:47'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, exactly. Going back to ELT vs ETL \\u2013 previously, these transformations\\\n",
      "    \\ might have been done outside the data warehouse, and now we're bringing it into\\\n",
      "    \\ the data warehouse. That's the biggest difference here. That transform layer\\\n",
      "    \\ is essentially operating within the destination and then does the transformation,\\\n",
      "    \\ creating new tables within the exact same destination.\"\n",
      "  sec: 1166\n",
      "  time: '19:26'\n",
      "  who: Natalie\n",
      "- header: Data lakes\n",
      "- line: And what is a data lake?\n",
      "  sec: 1190\n",
      "  time: '19:50'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, it's interesting because a data lake has some similarities to data\\\n",
      "    \\ warehouses. But a data lake is much more unstructured. When we think about data\\\n",
      "    \\ warehouses, they're all relational tables \\u2013 they all have set schemas.\\\n",
      "    \\ You can very easily pull from them using SQL. When we think about data lakes,\\\n",
      "    \\ they're a little bit more unstructured. I'd say the place that I've seen it\\\n",
      "    \\ become very useful is when I was at Keep Truckin\\u2019. We were in the IoT business,\\\n",
      "    \\ so we had a bigger warehouse and we had Snowflake. But the data that we had\\\n",
      "    \\ on all our customers weren\\u2019t always in the table format. We would sometimes\\\n",
      "    \\ be collecting videos using our hardware, and those are files. Those files are\\\n",
      "    \\ not things that data warehouses can store and read. That's something that really\\\n",
      "    \\ belongs in a data lake, which is a lot more unstructured and can support these\\\n",
      "    \\ different file types.\"\n",
      "  sec: 1192\n",
      "  time: '19:52'\n",
      "  who: Natalie\n",
      "- line: Basically, we just dump everything into a lake and then later figure out how\n",
      "    to actually make it cleaner, more organized, and more structured. Is that right?\n",
      "  sec: 1259\n",
      "  time: '20:59'\n",
      "  who: Alexey\n",
      "- line: \"Yes, it's definitely interesting at a very raw level. I know there are certain\\\n",
      "    \\ other terms like \\u2018data swamp\\u2019 or things that were, you know\\u2026\"\n",
      "  sec: 1271\n",
      "  time: '21:11'\n",
      "  who: Natalie\n",
      "- header: Data swamps\n",
      "- line: \"We actually have a question about this, \\u201CWhat is a data swamp? How can\\\n",
      "    \\ a lake become a swamp?\\u201D\"\n",
      "  sec: 1282\n",
      "  time: '21:22'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, I think when I've heard that term it's generally because there's maybe\\\n",
      "    \\ low quality or maybe very unrefined data. I've also heard this term refer to\\\n",
      "    \\ places or data lakes that have essentially become large places of just unused\\\n",
      "    \\ data. You put so much in there, and there's so little organization that it\\u2019\\\n",
      "    s very difficult to actually be able to utilize what\\u2019s in there. Maybe over\\\n",
      "    \\ time, especially as new people come in or people leave the team, it becomes\\\n",
      "    \\ harder and harder to manage what is there and what is usable. Yeah, I heard\\\n",
      "    \\ that term being used as a generic term to refer to data lakes that essentially\\\n",
      "    \\ have low quality data \\u2013 data that people can't trust.\"\n",
      "  sec: 1289\n",
      "  time: '21:29'\n",
      "  who: Natalie\n",
      "- header: Data governance\n",
      "- line: \"Yeah, there is another buzzword, \\u201Cdata governance\\u201D \\u2013 I guess\\\n",
      "    \\ this refers to making sure that your data lake doesn't become a swamp. When\\\n",
      "    \\ you make sure that the data is clean, what kind of data is there, everything\\\n",
      "    \\ is accounted for. So you just keep it more organized, I guess.\"\n",
      "  sec: 1341\n",
      "  time: '22:21'\n",
      "  who: Alexey\n",
      "- line: \"The data governance term also definitely applies to data warehouses. I have\\\n",
      "    \\ one company I worked at, we had this schema called \\u201Cad hoc.\\u201D Of course,\\\n",
      "    \\ people are going to throw things into \\u201Cad hoc\\u201D whenever they want\\\n",
      "    \\ \\u2013 there are no rules around it. So part of the data governance that we\\\n",
      "    \\ did was, \\u201CHow do we ensure that in certain databases or schemas, it's always\\\n",
      "    \\ clear what they're used for. It\\u2019s always clear how long things will stay\\\n",
      "    \\ there.\\u201D Because I've kind of married into the definition of \\u201CHow is\\\n",
      "    \\ this useful?\\u201D Of course, there's always this continual inspection of what\\\n",
      "    \\ is there, in order to ensure that it is still relevant or still will be used.\\\n",
      "    \\ Rather than having almost a trash bin that never gets empty. You want to make\\\n",
      "    \\ sure that your data warehouse or your data lake has that level of quality and\\\n",
      "    \\ relevance.\"\n",
      "  sec: 1368\n",
      "  time: '22:48'\n",
      "  who: Natalie\n",
      "- line: \"Maybe not a trash bin, I'm thinking about my basement, which has all the\\\n",
      "    \\ things that I don't need right now. I don't know what to do with them. I don't\\\n",
      "    \\ want to throw them away yet. So what to do with them? I'll just put them in\\\n",
      "    \\ my basement and figure out what to do with them later. You can do the same with\\\n",
      "    \\ data, right? \\u201CDo I need to track this data? Maybe I do. Let's track it.\\\n",
      "    \\ Let's keep this data.\\u201D Then one year later, you have this huge data source\\\n",
      "    \\ that nobody uses. So it becomes a swamp.\"\n",
      "  sec: 1427\n",
      "  time: '23:47'\n",
      "  who: Alexey\n",
      "- line: Yeah, exactly.\n",
      "  sec: 1463\n",
      "  time: '24:23'\n",
      "  who: Natalie\n",
      "- header: Ingestion layer vs Data lake\n",
      "- line: \"We also talked about the ingestion layer and the ingestion database. We talked\\\n",
      "    \\ about the data lake. I\\u2019m wondering \\u2013 to me, they look similar. First\\\n",
      "    \\ of all, are they similar? Are they the same? Or are those different things?\"\n",
      "  sec: 1464\n",
      "  time: '24:24'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, I think Evo actually came up with a good article on this too. Maybe\\\n",
      "    \\ we can put it in the links. She wrote about the difference and how they might\\\n",
      "    \\ be converging in some ways. I'd say there's still relevance for both. Data lakes\\\n",
      "    \\ are obviously going to be more flexible \\u2013 they're going to be able to support\\\n",
      "    \\ a lot more different file types and structures. That's the thing that data warehouses\\\n",
      "    \\ don't do. So there's a purpose for both. From what I've noticed, data warehouses\\\n",
      "    \\ are generally very helpful for smaller or intermediate-sized teams. As your\\\n",
      "    \\ needs grow and become more complex \\u2013 maybe your organization gets larger\\\n",
      "    \\ \\u2013 you may need to move to the data lake structure, which offers flexibility.\\\n",
      "    \\ As your team organization grows, it might be something that you have to weigh\\\n",
      "    \\ the pros and cons of, whether to even add a data lake as an addition, or potentially\\\n",
      "    \\ migrating fully to it. But a lot of the functionalities of the industry are\\\n",
      "    \\ allowing for the flexibility to choose between a data lake and a data warehouse.\"\n",
      "  sec: 1485\n",
      "  time: '24:45'\n",
      "  who: Natalie\n",
      "- line: \"Basically, the ingestion database is a part of a data warehouse, right? Maybe\\\n",
      "    \\ this is one of the tables in the data warehouse. Let's say we\\u2019re talking\\\n",
      "    \\ about Snowflake \\u2013 this can be one of the tables that are already in Snowflake.\\\n",
      "    \\ It's just that the end users, the business users or analysts, don't use this\\\n",
      "    \\ particular table, but it's still part of the warehouse. Is that right?\"\n",
      "  sec: 1556\n",
      "  time: '25:56'\n",
      "  who: Alexey\n",
      "- line: \"We were talking about the ingestion database. This is where we keep intermediate\\\n",
      "    \\ results. To me, a data lake also seems like a place where we keep intermediate\\\n",
      "    \\ results. So I was wondering \\u2013 are the ingestion layers part of the data\\\n",
      "    \\ warehouse or not?\"\n",
      "  who: Alexey\n",
      "- line: \"I think in the analytics team framework, it generally is ingesting into a\\\n",
      "    \\ data warehouse, not a data lake. Because they're generally dealing with different\\\n",
      "    \\ APIs, different sources, and then doing that transformation there and, of course,\\\n",
      "    \\ doing the visualization on top. From an analytics team perspective, I think\\\n",
      "    \\ the data warehouse is the most relevant. Where it may not be as relevant is\\\n",
      "    \\ maybe for engineering teams, who need data lakes to power parts of their application,\\\n",
      "    \\ or maybe data science teams who need to parse through lots of data that isn't\\\n",
      "    \\ necessarily in a structured format in order to do their analysis. I think it\\\n",
      "    \\ depends on your business use case, what kind of team you're on, and what is\\\n",
      "    \\ helpful for you. You have to make that call \\u2013 what are the capabilities\\\n",
      "    \\ that you really need to get your work done? Essentially, you choose the solution\\\n",
      "    \\ from there.\"\n",
      "  sec: 1607\n",
      "  time: '26:47'\n",
      "  who: Natalie\n",
      "- header: Do you need both a Data warehouse and a Data lake?\n",
      "- line: \"We have a question \\u2013 \\u201CDo we need to have both a data lake and a\\\n",
      "    \\ data warehouse?\\u201D I think, from what I understood, the answer was \\u201C\\\n",
      "    Yes.\\u201D Right? We have the raw data in the lake. We have prepared data in a\\\n",
      "    \\ data mart in a data warehouse. Then if somebody such as data scientists, like\\\n",
      "    \\ you said in your example \\u2013 if they need to parse through raw data, they\\\n",
      "    \\ can just go ahead and do it.\"\n",
      "  sec: 1659\n",
      "  time: '27:39'\n",
      "  who: Alexey\n",
      "- line: \"I don\\u2019t think you need to have both. We don't necessarily need it in\\\n",
      "    \\ our business to have both. It really depends on the complexity of your business.\\\n",
      "    \\ From an analytics perspective, generally, if I'm in the analytics team, I probably\\\n",
      "    \\ will never touch a data lake. I\\u2019ll probably operate within the data warehouse.\\\n",
      "    \\ But I know that there are teams within the organization that might rely on more\\\n",
      "    \\ of a data lake structure instead. I think it really depends on the complexity\\\n",
      "    \\ of the business and what different teams need.\"\n",
      "  sec: 1687\n",
      "  time: '28:07'\n",
      "  who: Natalie\n",
      "- line: Yeah. I prepared a question, but I think you already answered it. Let me ask\n",
      "    the question and maybe I can answer it and then you tell me if I'm right.\n",
      "  sec: 1718\n",
      "  time: '28:38'\n",
      "  who: Alexey\n",
      "- line: Sure.\n",
      "  sec: 1729\n",
      "  time: '28:49'\n",
      "  who: Natalie\n",
      "- line: \"Let's say we have an ecommerce online shop. We want to track some events\\\n",
      "    \\ there \\u2013 so clicks. Every time a user comes to our online shop and selects\\\n",
      "    \\ a product, clicks on this product, we track this event. These events \\u2013\\\n",
      "    \\ these clicks \\u2013 they end up in the data lake where we keep the clicks. I\\\n",
      "    \\ have a bunch of SQL queries to transform these clicks into something else \\u2013\\\n",
      "    \\ so aggregate, calculate some statistics. I'm a data scientist, so what I do\\\n",
      "    \\ is run some machine learning on top of these clicks. For example, I have a model\\\n",
      "    \\ that wants to predict how many clicks there will be for each product. So I need\\\n",
      "    \\ to use this information about the clicks. I write some SQL queries, extract\\\n",
      "    \\ these clicks, and I build the model for that. Maybe instead of building a model,\\\n",
      "    \\ I just put the clicks into a dashboard. Then the top management sees \\u201C\\\n",
      "    Okay, in this category, we have that many clicks. In that category, we have that\\\n",
      "    \\ many clicks.\\u201D Then to orchestrate everything, in our company at least,\\\n",
      "    \\ we typically use Airflow for all these things.\"\n",
      "  sec: 1730\n",
      "  time: '28:50'\n",
      "  who: Alexey\n",
      "- line: \"So the question is, \\u201CIs this ETL, or ELT?\\u201D I think \\u2013 let me\\\n",
      "    \\ answer this and you correct me \\u2013 I think this is ELT. Because first, we\\\n",
      "    \\ dump everything into a data lake \\u2013 we don't change the raw events. We leave\\\n",
      "    \\ them be in the data lake. Then there are other jobs \\u2013 other transformation\\\n",
      "    \\ jobs \\u2013 that take the raw data, transform, and then eventually put this\\\n",
      "    \\ in a model or in a dashboard. Right?\"\n",
      "  who: Alexey\n",
      "- line: Exactly. Yeah. You're not using a tool to do that transformation. You yourself\n",
      "    are taking all the data that has been loaded into your area, and then doing something\n",
      "    with it. Exactly.\n",
      "  sec: 1844\n",
      "  time: '30:44'\n",
      "  who: Natalie\n",
      "- line: \"Yeah. All this time I thought that Airflow was an ETL tool, but it\\u2019\\\n",
      "    s actually an ELT tool, right?\"\n",
      "  sec: 1859\n",
      "  time: '30:59'\n",
      "  who: Alexey\n",
      "- line: \"Airflow? Yeah, I think it's very much like an orchestrator. It also helps\\\n",
      "    \\ to just schedule. But ultimately, yeah. Everybody has a very good integration\\\n",
      "    \\ with Airflow that essentially runs your Airbyte jobs, using Airflow. So yeah\\\n",
      "    \\ \\u2013 we also use Airflow here.\"\n",
      "  sec: 1872\n",
      "  time: '31:12'\n",
      "  who: Natalie\n",
      "- header: Airbyte and ELT\n",
      "- line: \"I think you mentioned at the beginning what Airbyte does \\u2013 it's about\\\n",
      "    \\ transformation, right? It's about ingesting and then putting it into a data\\\n",
      "    \\ warehouse. Maybe now we can try to make sense from all these buzzwords. We know\\\n",
      "    \\ what the transformation means. This is taking the data and changing it a little\\\n",
      "    \\ bit. Then ingestion is about putting something into a data warehouse. Then a\\\n",
      "    \\ data warehouse is basically the database that we use for all these analytical\\\n",
      "    \\ purposes. So yeah, maybe you can tell us now what Airbyte does?\"\n",
      "  sec: 1891\n",
      "  time: '31:31'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, so everybody tackles the E-L part. That's our main goal \\u2013 to ensure\\\n",
      "    \\ that the E-L is as seamless and reliable as any other product on the market\\\n",
      "    \\ and that you have a great understanding and expectation of what the output in\\\n",
      "    \\ your data warehouse is going to be. We also integrate really well with DBT,\\\n",
      "    \\ right within the product. So we're not handling the transformation ourselves,\\\n",
      "    \\ per se, but we're relying on DBT as a part of our product to ensure that analysts\\\n",
      "    \\ can use DBT to do those SQL transformations once the data is there. We're not\\\n",
      "    \\ like a transform product necessarily, but we just integrate really well with\\\n",
      "    \\ that and have embedded that into our product.\"\n",
      "  sec: 1931\n",
      "  time: '32:11'\n",
      "  who: Natalie\n",
      "- line: \"One thing I didn't actually mention earlier is that Airbyte is also open\\\n",
      "    \\ source. We are really focused on building our community, enabling users \\u2013\\\n",
      "    \\ people out there who are excited to contribute back to our project \\u2013 to\\\n",
      "    \\ enable those people to actually build out potentially new connectors or maybe\\\n",
      "    \\ even amend existing ones, and contribute back to our project.\"\n",
      "  who: Natalie\n",
      "- line: DBT is also open source, right?\n",
      "  sec: 2011\n",
      "  time: '33:31'\n",
      "  who: Alexey\n",
      "- line: Yes, exactly. DBT is also open source. It's part of that modern data stack,\n",
      "    you could say, for the evolution towards more open source tools. They also have\n",
      "    a cloud product.\n",
      "  sec: 2013\n",
      "  time: '33:33'\n",
      "  who: Natalie\n",
      "- header: Modern data stack\n",
      "- line: \"Yeah. So speaking of this modern stack, I've heard this term many times and\\\n",
      "    \\ actually we have a talk about this quite soon. It's about this modern stack\\\n",
      "    \\ for analytics. Actually the talk we have is \\u201Cmodern data stack for analytics\\\n",
      "    \\ engineering.\\u201D I don't know if there are different stacks for analytics\\\n",
      "    \\ and for analytics engineering \\u2013 probably they\\u2019re the same. So, what\\\n",
      "    \\ is it? Can you tell us a bit about it? Which tools are a part of this stack?\\\n",
      "    \\ Why do we even talk about it? Why is it a thing?\"\n",
      "  sec: 2025\n",
      "  time: '33:45'\n",
      "  who: Alexey\n",
      "- line: \"So why it's a thing \\u2013 because essentially, you are now able to choose\\\n",
      "    \\ each piece of the stack individually instead of having a platform approach where\\\n",
      "    \\ \\u201Cone fits all\\u201D \\u2013 where you have a lot of vendor lock-in. You\\\n",
      "    \\ now get to choose the best of breed for each of the pieces of the data puzzle.\\\n",
      "    \\ For extract and load obviously, there's Airbyte. There are also incomes like\\\n",
      "    \\ Fivetran that have been around for quite a bit longer. From a data warehousing\\\n",
      "    \\ perspective, you have Snowflake, you have Databricks, BigQuery, Amazon Redshift.\\\n",
      "    \\ Then for transformation, you have DBT. Outside of DBT and all the features it\\\n",
      "    \\ provides, you could just write SQL and that would also work as well. Then from\\\n",
      "    \\ a visualization perspective, we see new tools like Superset being adopted fairly\\\n",
      "    \\ well. Then obviously, incumbents like Looker, or even Tableau. The idea of the\\\n",
      "    \\ modern data stack is that instead of having one solution that tries to do it\\\n",
      "    \\ all, you're essentially picking and choosing the one that really fits with what\\\n",
      "    \\ you need the best.\"\n",
      "  sec: 2063\n",
      "  time: '34:23'\n",
      "  who: Natalie\n",
      "- line: So basically, it's a bunch of tools that work really well together.\n",
      "  sec: 2138\n",
      "  time: '35:38'\n",
      "  who: Alexey\n",
      "- header: Reverse ETL\n",
      "- line: Yeah, and of course, we can't forget Airflow, which does a lot of the orchestration.\n",
      "    Then there's also this emerging space of reverse ETL, where you'll have tools\n",
      "    like Hightouch or Census, and even Airbyte is thinking about going into this space\n",
      "    as well.\n",
      "  sec: 2142\n",
      "  time: '35:42'\n",
      "  who: Natalie\n",
      "- line: \"Yeah, so can you tell us a bit more about this \\u201Creverse ETL\\u201D? Or\\\n",
      "    \\ should it be reverse ETL or reverse ELT? Or what is that anyways? Why is it\\\n",
      "    \\ reverse? Why would you want to reverse it?\"\n",
      "  sec: 2162\n",
      "  time: '36:02'\n",
      "  who: Alexey\n",
      "- line: \"=In the past, what I've seen data teams use is maybe a Python wrapper to\\\n",
      "    \\ push data back into Salesforce. These \\u201Creverse ETL\\u201D tools are enabling\\\n",
      "    \\ really low-code solutions for salespeople or marketers to actually come and\\\n",
      "    \\ just kind of \\u201Cpoint and click\\u201D and say, \\u201CI want to copy this\\\n",
      "    \\ table and the output of this table in this data warehouse and bring it back\\\n",
      "    \\ into my source system to be able to action on it.\\u201D You don't have to be\\\n",
      "    \\ technical \\u2013 it's pretty low-code or no code. That's really something that's\\\n",
      "    \\ very powerful, because it essentially allows analytics to be a function within\\\n",
      "    \\ the organization itself. It allows analysts to really be very aligned with what\\\n",
      "    \\ the business needs.\"\n",
      "  sec: 2174\n",
      "  time: '36:14'\n",
      "  who: \"Reverse ETL is definitely something that a lot of data teams are trying to\\\n",
      "    \\ already solve today using custom scripts that bring a lot of that analysis that\\\n",
      "    \\ analytics teams do. It also brings that back into the operational systems that\\\n",
      "    \\ business users actually need that data in. One good example is \\u2013 let's\\\n",
      "    \\ say that an analytics team is working on a lead scoring model. Essentially,\\\n",
      "    \\ it says, \\u201CI have 100 leads. I rank them using behavioral data, demographic\\\n",
      "    \\ data. I take this information and I rate these leads from 1 to 100 on what the\\\n",
      "    \\ priority is \\u2013 who you should reach out to.\\u201D Traditionally, that data\\\n",
      "    \\ would just live in a data warehouse and maybe in a visualization tool too. If\\\n",
      "    \\ I'm a salesperson, I need that data in the system that I'm using to actually\\\n",
      "    \\ action on it.\"\n",
      "- line: \"Basically, before, engineers would need to write a bunch of scripts for doing\\\n",
      "    \\ this. This is emphasized in the healthcare APIs that allow them to push the\\\n",
      "    \\ data there. But I guess it's not easy to maintain these scripts and it's also\\\n",
      "    \\ not the core business of the companies to do that. So there are some tools that\\\n",
      "    \\ actually allow you to have this drag-and-drop experience, so you can say, \\u201C\\\n",
      "    Okay, this data from this table in my BigQuery or Snowflake should go in my Salesforce\\\n",
      "    \\ or something else.\\u201D Right?\"\n",
      "  sec: 2281\n",
      "  time: '38:01'\n",
      "  who: Alexey\n",
      "- line: \"Exactly. Yeah. I would still consider this reverse-ETL, not reverse-ELT,\\\n",
      "    \\ because that transformation is not happening in that source where you're pushing\\\n",
      "    \\ it back to. The transformation is still happening before you move it out of\\\n",
      "    \\ the database. Really, it's like a porting of the more finalized\\u2026 maybe\\\n",
      "    \\ you could even call it a data mart and bring it back into the source. No transformation\\\n",
      "    \\ is actually happening in the source system itself.\"\n",
      "  sec: 2316\n",
      "  time: '38:36'\n",
      "  who: Natalie\n",
      "- header: Is drag-and-drop killing data engineering jobs?\n",
      "- line: \"To make sure I understood the whole picture: we have some of these tools\\\n",
      "    \\ like Google AdWords \\u2013 all these systems, like Google AdWords, or Facebook\\\n",
      "    \\ Ads, or whatever. We first need to take the data from there and import \\u2013\\\n",
      "    \\ put it into our data warehouse or ingest. We import and then we do something\\\n",
      "    \\ and then we export back, right? Or using the terminology we just learned, we\\\n",
      "    \\ first extract, then do something, and then we do this reverse extract, and then\\\n",
      "    \\ put that back.\"\n",
      "  sec: 2346\n",
      "  time: '39:06'\n",
      "  who: Alexey\n",
      "- line: \"Speaking of this low-code/no-code, we have a question related to that. \\u201C\\\n",
      "    Is the data engineering job dying with all these tools that give a drag-and-drop\\\n",
      "    \\ experience? Since you can do these kinds of drag-and-drop data pipelines with\\\n",
      "    \\ all these built integrations?\"\n",
      "  who: Alexey\n",
      "- line: \"I would not say dying, I think it is very much evolving. I think in data\\\n",
      "    \\ engineering, these tools are essentially allowing for the more mundane parts\\\n",
      "    \\ of data engineers\\u2019 job to disappear and allow for them to focus on other\\\n",
      "    \\ things. For example, in my team at Keep Truckin\\u2019, our data engineer was\\\n",
      "    \\ very much focused on a lot more data infrastructure pieces, instead of being\\\n",
      "    \\ focused on managing pipelines and waking up in the morning, and feeling like,\\\n",
      "    \\ \\u201COh, these pipelines have broken, and I need to go fix that. This field\\\n",
      "    \\ was deleted.\\u201D It was more around tooling for the analytics team \\u2013\\\n",
      "    \\ ensuring that we have proper data governance pieces in place.\"\n",
      "  sec: 2413\n",
      "  time: '40:13'\n",
      "  who: Natalie\n",
      "- line: \"There are a lot of things that really are beyond the technical scope of even\\\n",
      "    \\ maybe any analytics engineer or an analyst \\u2013 where a data engineer most\\\n",
      "    \\ definitely can enable that data team to be operating very efficiently. Something\\\n",
      "    \\ like common code standards, being able to bring the analytics team to a place\\\n",
      "    \\ where they can be pushing out in a nearly-continuous delivery process. They\\u2019\\\n",
      "    re ensuring that there's validation of the code and that pipelines aren't breaking\\\n",
      "    \\ from the data team and what they're producing. There are a lot of pieces that\\\n",
      "    \\ I think the data engineer can now actually go and tackle that the analytics\\\n",
      "    \\ team might not necessarily be very focused on. But without these things, they\\\n",
      "    \\ actually can't be successful.\"\n",
      "  who: Natalie\n",
      "- line: \"We talked about these scripts that people would write before reverse ETL\\\n",
      "    \\ tools existed. I imagined that maintaining the scripts was a nightmare because\\\n",
      "    \\ they break in unpredictable ways. For example the API changes and then all your\\\n",
      "    \\ scripts are not working. Then you have to deal with all these intricacies \\u2013\\\n",
      "    \\ I\\u2019m guessing that this is not fun at all. A data engineer would probably\\\n",
      "    \\ rather focus on other things. I'm not a data engineer, but I don't really want\\\n",
      "    \\ to even think about maintaining scripts for talking to some third party tools\\\n",
      "    \\ like Salesforce and trying to maintain them. Yeah, I'd rather focus on something\\\n",
      "    \\ else. I guess this is why these tools are quite useful and why people love them.\\\n",
      "    \\ Data engineers are still happy \\u2013 nobody is going to fire them anytime soon.\"\n",
      "  sec: 2520\n",
      "  time: '42:00'\n",
      "  who: Alexey\n",
      "- line: Yeah.\n",
      "  sec: 2581\n",
      "  time: '43:01'\n",
      "  who: Natalie\n",
      "- header: Who is responsible for managing unused data?\n",
      "- line: \"Okay, thanks. We have some more questions. The question is \\u201C70-90% of\\\n",
      "    \\ beta in many organizations is collected but never used. Who is responsible for\\\n",
      "    \\ taking care of that and for noticing that? Data engineers? How should we actually\\\n",
      "    \\ go about noticing things like that?\\u201D\"\n",
      "  sec: 2582\n",
      "  time: '43:02'\n",
      "  who: Alexey\n",
      "- line: \"If I can think back to my time when I took on more of that analytics manager\\\n",
      "    \\ role, I would say it's very much a team effort. It's hard to know what is not\\\n",
      "    \\ being used if you don't have the business analysts there trying to speak to,\\\n",
      "    \\ \\u201CWhat are the use cases that we're solving for in that business today?\\u201D\\\n",
      "    \\ And then tracing that back to the ingestion layer, \\u201CWhat is a dependency\\\n",
      "    \\ of those use cases? In order to figure out what isn't being used \\u2013 I remember\\\n",
      "    \\ how we would try to do this on a quarterly or monthly cleanup level \\u2013 we\\\n",
      "    \\ really try to take a critical look as a team. It wouldn't be on a single person\\\n",
      "    \\ to really be responsible to know everything, because that's impossible. We would\\\n",
      "    \\ really rely a lot on the business analyst and I guess the analytics engineers\\\n",
      "    \\ to have them understand and be able to trace back to what is actually being\\\n",
      "    \\ used and what are things that may not be used today, but might be used in the\\\n",
      "    \\ future. So you always want to have that forward-looking piece too. Of course,\\\n",
      "    \\ this whole idea of ELT is that you have all the data there, and it maybe might\\\n",
      "    \\ not be used now, but potentially. If there's a use case for that in the future,\\\n",
      "    \\ someone should speak to that.  I don't think it should ever be on one person.\\\n",
      "    \\ I think that would be a pretty difficult role to have if it was, because that\\\n",
      "    \\ person would be missing the context of the actual business.\"\n",
      "  sec: 2617\n",
      "  time: '43:37'\n",
      "  who: Natalie\n",
      "- line: \"The person who doesn't miss this context \\u2013 who has the context \\u2013\\\n",
      "    \\ would be an analytics engineer, perhaps or an analyst. Right?\"\n",
      "  sec: 2718\n",
      "  time: '45:18'\n",
      "  who: Alexey\n",
      "- line: \"I think it's both the business analyst and the analytics engineer. Because\\\n",
      "    \\ the business analyst might be really focused and working with the business,\\\n",
      "    \\ but they might not know as much about the pipelining. So they need to work together\\\n",
      "    \\ to ensure that they both have a mutual understanding. Then whoever is in charge\\\n",
      "    \\ of managing the data governance, the cleanliness of the database, then they\\\n",
      "    \\ need to communicate with them that, \\u201CHey, this is data that's not currently\\\n",
      "    \\ being used,\\u201D and then execute on cleaning it up from there.\"\n",
      "  sec: 2728\n",
      "  time: '45:28'\n",
      "  who: Natalie\n",
      "- header: \"CDC \\u2013 Change Data Capture\"\n",
      "- line: \"Thank you. Another question we have is, \\u201CI have no idea what CDC is.\\\n",
      "    \\ Do you know what CDC is?\\u201D\"\n",
      "  sec: 2759\n",
      "  time: '45:59'\n",
      "  who: Alexey\n",
      "- line: \"Yeah. It's \\u201Cchange data capture.\\u201D That's a feature that is available\\\n",
      "    \\ in our connectors. CDC is essentially a way to be able to capture only changed\\\n",
      "    \\ records. That's where the recording product comes from. Essentially, what it\\\n",
      "    \\ allows you to do is avoid having to fully replicate your database every time.\\\n",
      "    \\ Instead, let's say, I sync my database today \\u2013 tomorrow, only 10% of those\\\n",
      "    \\ rows have changed. I only want to sync those 10%. And I only want to capture\\\n",
      "    \\ those 10% that have changed and then only update those 10% in my destination.\\\n",
      "    \\ Without Changed Data Capture, you might have to be doing a whole replication\\\n",
      "    \\ every day. That isn't really the optimal way to manage cloud resources, because\\\n",
      "    \\ you're consuming more resources to do that replication. By doing CDC, you actually\\\n",
      "    \\ have the ability to reduce your own cloud costs if you're self-hosting. But\\\n",
      "    \\ also, it's just much faster because you're moving less data.\"\n",
      "  sec: 2771\n",
      "  time: '46:11'\n",
      "  who: Natalie\n",
      "- line: \"I'm trying to think of an example. I work at OLX, an online marketplace.\\\n",
      "    \\ This is a place, let's say, if you want to sell your phone, you go create a\\\n",
      "    \\ listing. Sometimes users \\u2013 the sellers \\u2013 can go and change the title,\\\n",
      "    \\ or they can go and change the price. I guess this CDC (Change Data Capture)\\\n",
      "    \\ will allow us to see\\u2026 let\\u2019s say if we have 30 million active listings\\\n",
      "    \\ right now on the website \\u2013 we don't want to look at the entire database\\\n",
      "    \\ of listings. If something changes, if the prices change or titles change, we\\\n",
      "    \\ just want to see that and keep the delta (difference between the old version\\\n",
      "    \\ and the changes). Or we keep only the new thing instead of taking all the 30\\\n",
      "    \\ million records and keeping them over and over again. Is that right?\"\n",
      "  sec: 2846\n",
      "  time: '47:26'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, exactly. It\\u2019s essentially a performance consideration. It also\\\n",
      "    \\ allows you to capture deleted rows. So that's another benefit as well. I think\\\n",
      "    \\ that we don't offer it on all of our data warehouse sources yet. But we are\\\n",
      "    \\ actively working on building out CDC capabilities for all the sources that essentially\\\n",
      "    \\ allow for that.\"\n",
      "  sec: 2910\n",
      "  time: '48:30'\n",
      "  who: Natalie\n",
      "- header: Slowly changing dimension\n",
      "- line: \"Do you know what a \\u201Cslowly changing dimension\\u201D is? I\\u2019ve heard\\\n",
      "    \\ this term a few times. I'm curious what this is.\"\n",
      "  sec: 2938\n",
      "  time: '48:58'\n",
      "  who: Alexey\n",
      "- line: Yeah, I can speak to what I think it means.\n",
      "  sec: 2945\n",
      "  time: '49:05'\n",
      "  who: Natalie\n",
      "- line: I'm also not 100% sure what it actually is, but I hear this term used many\n",
      "    times.\n",
      "  sec: 2950\n",
      "  time: '49:10'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, I think in the business, you will probably start a pipeline process\\\n",
      "    \\ with maybe 10 columns that you know you need. Maybe over time, if let's say\\\n",
      "    \\ a salesperson says, \\u201COh, I'm actually now going to collect information\\\n",
      "    \\ on whether or not they'd be interested in this new product feature we just launched.\\u201D\\\n",
      "    \\ And they added maybe a checkbox or maybe a picklist in Salesforce. The slowly\\\n",
      "    \\ changing dimension to me, when I hear that term, means your dimensions may change\\\n",
      "    \\ over time as your business changes. Now that the sales team is collecting new\\\n",
      "    \\ information, you also want to ingest that new information into your data warehouse.\\\n",
      "    \\ That will mean that your dimensions change and that you will actually want to\\\n",
      "    \\ adjust not just 10 fields, but now 11. Then maybe next week it's 12, because\\\n",
      "    \\ now they're collecting something else, or there's another piece of data that's\\\n",
      "    \\ relevant to what you need. That's what I think of when I hear that. I hope that\\\n",
      "    \\ answers the question.\"\n",
      "  sec: 2957\n",
      "  time: '49:17'\n",
      "  who: Natalie\n",
      "- line: \"Well, I think the example you gave about a new product feature that a user\\\n",
      "    \\ is interested in \\u2013 this user is currently interested in this feature, but\\\n",
      "    \\ maybe in one year, the user is no longer interested. I guess this doesn't change\\\n",
      "    \\ quickly \\u2013 it changes slowly, right?\"\n",
      "  sec: 2418\n",
      "  time: '40:18'\n",
      "  who: Alexey\n",
      "- line: \"Well, when I think about dimensions, to me, it's like adding a new column\\\n",
      "    \\ in a table structure \\u2013 the value of that column, the field might change.\\\n",
      "    \\ So that's kind of like capturing the history of the field. But ultimately, the\\\n",
      "    \\ way to think about it is, you're actually capturing an additional dimension\\\n",
      "    \\ of data that you weren't capturing before. I don't think that that ever happens\\\n",
      "    \\ all at once in a business. A business is constantly evolving and changing, especially\\\n",
      "    \\ if you're small and you're in that growth phase. You're constantly trying to\\\n",
      "    \\ think of new things to track, maybe launching new products or new product features.\\\n",
      "    \\ There's always going to be this ever-changing and growing set of dimensions\\\n",
      "    \\ that you'll want to track and that's where the \\u201Cslowly changing dimensions\\u201D\\\n",
      "    \\ aspect comes into place.\"\n",
      "  sec: 2439\n",
      "  time: '40:39'\n",
      "  who: Natalie\n",
      "- header: Are there cases where ETL is preferable over ELT?\n",
      "- line: Do you know of any examples when we still would prefer ETL over ELT?\n",
      "  sec: 2490\n",
      "  time: '41:30'\n",
      "  who: Alexey\n",
      "- line: \"I would say \\u2013 if there's a large enterprise need for it. I personally\\\n",
      "    \\ can't speak to being in a major enterprise company and having a need for this,\\\n",
      "    \\ but it might be needed there. It might be something that much larger enterprises\\\n",
      "    \\ might want to adopt. I think that is kind of the play where ETL has really been\\\n",
      "    \\ successful \\u2013 in these large enterprises. Where you're potentially combining\\\n",
      "    \\ multiple data warehouses or data sources and bringing them together, and then\\\n",
      "    \\ pushing them out to multiple data warehouses or lakes. So maybe there's a need\\\n",
      "    \\ for this kind of intermediary place, maybe a staging area, where you need to\\\n",
      "    \\ ingest from a lot and then you need to propagate out a lot.\"\n",
      "  sec: 2500\n",
      "  time: '41:40'\n",
      "  who: Natalie\n",
      "- line: Yeah, I think I worked at an enterprise and we had all these tools like Oracle,\n",
      "    Informatica, and all these kinds of things. I'm pretty sure if I come back now\n",
      "    and see what they use it's still Oracle and Informatica. It's been working for\n",
      "    them pretty well at the bank where I worked. We were processing a lot of data\n",
      "    there.\n",
      "  sec: 2558\n",
      "  time: '42:38'\n",
      "  who: Alexey\n",
      "- line: Yeah. If there's a certain use case for it. The place that I could see a use\n",
      "    case for that kind of staging area and that really complex model, is that intermediary\n",
      "    that essentially allows you to message things from many places to one and then\n",
      "    from one to many again. I think smaller companies don't generally have that need\n",
      "    as strongly but much more complex organizations might be using a different warehouse\n",
      "    for every business unit, or a different data lake to service different teams.\n",
      "    That might be where they need some sort of intermediary solution.\n",
      "  sec: 2584\n",
      "  time: '43:04'\n",
      "  who: Natalie\n",
      "- header: Why is Airbyte open source?\n",
      "- line: \"Thank you. The last question they prepared for you was about\\u2026 we talked\\\n",
      "    \\ about open source, that Airbyte is open source, and we also talked about DBT\\\n",
      "    \\ being open source. Do you know why Airbyte is open source? Why make it open\\\n",
      "    \\ source? Aren't you afraid that somebody will come and just steal your code?\"\n",
      "  sec: 2625\n",
      "  time: '43:45'\n",
      "  who: Alexey\n",
      "- line: \"Your first question of \\u201CWhy open source?\\u201D I really think that this\\\n",
      "    \\ is the way forward for this space. When you look at incumbents in the place\\\n",
      "    \\ like Fivetran, they're never going to be able to support the long tail of connectors\\\n",
      "    \\ that really exists out there. This explosion of tools that we're seeing in pretty\\\n",
      "    \\ much every space means that every tool has an API, they are all housing your\\\n",
      "    \\ business data, and all of that data is really relevant. But there's kind of\\\n",
      "    \\ a long tail of connectors that may not be like NetSuite, or like AdWords, like\\\n",
      "    \\ these really popular ones, but maybe less popular ones that people are still\\\n",
      "    \\ using and experimenting with and trying out and growing with. Those need to\\\n",
      "    \\ be supported too. Right now, what we're seeing in this space \\u2013 and this\\\n",
      "    \\ is how I like to think Airbyte actually came to be \\u2013 our founders did a\\\n",
      "    \\ bunch of interviews, what they heard was, \\u201CYeah, we're using Fivetran or\\\n",
      "    \\ Stitch. But we're still writing our own pipelines. We're still building things\\\n",
      "    \\ on the side. We're still managing these numbers of scripts that tackle that\\\n",
      "    \\ long tail, because the business still needs that data.\\u201D\"\n",
      "  sec: 2652\n",
      "  time: '44:12'\n",
      "  who: Natalie\n",
      "- line: That's not the future that we see. We want our community and us to enable\n",
      "    that community to really be able to support the many connectors that should exist\n",
      "    out there. We don't see something like a closed source project being able to support\n",
      "    that. Being open source enables us to work like we have many hands, so to say.\n",
      "    When people contribute, we accelerate at such a higher velocity that we can actually\n",
      "    become the standard for data integration.\n",
      "  who: Natalie\n",
      "- line: \"So basically, if I use some proprietary tool and I use something that this\\\n",
      "    \\ proprietary tool doesn't support \\u2013 some very unpopular system that, for\\\n",
      "    \\ some reasons, we use at work. We need to be able to extract data from there.\\\n",
      "    \\ If I use something like Fivetran, as you mentioned, or Stitch, they can say,\\\n",
      "    \\ \\u201CYeah, we will consider implementing this in five years\\u2026 or never.\\u201D\\\n",
      "    \\ But if you use an open source tool a developer can actually just go ahead and\\\n",
      "    \\ implement and then plug this thing into existing infrastructure and it just\\\n",
      "    \\ works. Is that right? Is that the main idea?\"\n",
      "  sec: 2766\n",
      "  time: '46:06'\n",
      "  who: Alexey\n",
      "- line: We do see a lot of people actually plugging in their custom connectors. We\n",
      "    have a place in the UI where you just add a new source. We have a CDK (connector\n",
      "    development kit) to enable people to build things themselves and it's very flexible.\n",
      "    People can essentially fork our project and bring in custom connectors that they\n",
      "    have. Maybe custom business logic or things that they want to ingrain into their\n",
      "    connector, so they use Airbyte that way.\n",
      "  sec: 2812\n",
      "  time: '46:52'\n",
      "  who: Natalie\n",
      "- line: \"To your second question, though, I think\\u2026 We are open source and we\\\n",
      "    \\ always want to enable our long-term connectors to be available to anyone to\\\n",
      "    \\ use. We want to make it super easy for small or medium-sized teams to just get\\\n",
      "    \\ that basic functionality of being able to be supported by connectors anytime.\\\n",
      "    \\ We'll always have our connectors be open source. We are coming to the market\\\n",
      "    \\ with a cloud offering which is more that enterprise set of features like SSO,\\\n",
      "    \\ certain things around security like RBAC (role based access control), and other\\\n",
      "    \\ features that generally larger enterprise teams will want. For a small team\\\n",
      "    \\ or a single developer, they don't necessarily have a need for these, but they\\\n",
      "    \\ just want to get up and running very quickly with connectors and moving data.\\\n",
      "    \\ That's the part that will always be a part of our mission and goal.\"\n",
      "  who: Natalie\n",
      "- header: The case of Elasticsearch and AWS\n",
      "- line: Have you heard about this story about Elasticsearch and AWS? I think everyone\n",
      "    whose model has open sourcing in their code probably heard about this story. But\n",
      "    for those who don't know, Elasticsearch had their own cloud offering. So if you\n",
      "    don't want to maintain your own cluster of Elasticsearch servers, you just go\n",
      "    to Elasticsearch and use a managed solution. Then one day, AWS decided that they\n",
      "    also want to provide a managed solution of ElasticSearch. Now Elasticsearch has\n",
      "    a problem, right? Because AWS just took their code and deployed it. Now, people\n",
      "    will go to AWS, for example, instead of going to Elasticsearch for a managed solution.\n",
      "    So, are you not afraid that something like this can happen? That somebody will\n",
      "    basically do the same thing? And because you're open source, they can actually\n",
      "    just do this.\n",
      "  sec: 2906\n",
      "  time: '48:26'\n",
      "  who: Alexey\n",
      "- line: \"Yeah, it's definitely something that we think very carefully about. The things\\\n",
      "    \\ that we talk about internally are \\u201CAre we under the right license? We're\\\n",
      "    \\ currently under MIT. Is this the right license for us moving forward, especially\\\n",
      "    \\ as we launch cloud?\\u201D These are definitely things that we consider very\\\n",
      "    \\ carefully. I think probably there\\u2019s more to come soon in the coming month\\\n",
      "    \\ on that \\u2013 on whether we have to make any changes or not. But that\\u2019\\\n",
      "    s definitely something that we actively discuss internally.\"\n",
      "  sec: 2972\n",
      "  time: '49:32'\n",
      "  who: Natalie\n",
      "- line: \"Yeah, I guess many open source companies are starting to think about this.\\\n",
      "    \\ This story of AWS and Elasticsearch \\u2013 new things keep appearing. Now, all\\\n",
      "    \\ of a sudden, Elasticsearch are the bad people because they are starting to hide\\\n",
      "    \\ things, they are starting to close source some things. I\\u2019m curious to see\\\n",
      "    \\ how it will end and I hope Elasticsearch figures it out.\"\n",
      "  sec: 3605\n",
      "  time: '1:00:05'\n",
      "  who: Alexey\n",
      "- line: Do you have any last words before we finish?\n",
      "  sec: 3636\n",
      "  time: '1:00:36'\n",
      "  who: Alexey\n",
      "- header: Conclusion\n",
      "- line: \"It was such a pleasure to be on this, talking about these acronyms. I hope\\\n",
      "    \\ it helped some of your listeners get more clarity. Airbyte \\u2013 check us out.\\\n",
      "    \\ We are also hiring on a lot of different fronts. Not just on the engineering\\\n",
      "    \\ front, but also within the go-to-market side as well. So check us out. Our entire\\\n",
      "    \\ handle gets listed on our company docs page \\u2013 very public. If you want\\\n",
      "    \\ to contribute back or check us out, you can do that very easily. All the information\\\n",
      "    \\ is on our website.\"\n",
      "  sec: 3642\n",
      "  time: '1:00:42'\n",
      "  who: Natalie\n",
      "- line: Thank you. How can people find you if they have a question?\n",
      "  sec: 3677\n",
      "  time: '1:01:17'\n",
      "  who: Alexey\n",
      "- line: For me, just on LinkedIn - Natalie Kwong. That is the best place to find me.\n",
      "  sec: 3680\n",
      "  time: '1:01:20'\n",
      "  who: Natalie\n",
      "- line: Ok. Thanks a lot. Thanks for joining us today. Thanks for telling us about\n",
      "    acronyms. Now I can make sense of them and hopefully, everyone else can as well.\n",
      "    Thanks, everyone, for joining us and for asking questions and for watching us.\n",
      "  sec: 3689\n",
      "  time: '1:01:29'\n",
      "  who: Alexey\n",
      "\n",
      "---\n",
      "\n",
      "\n",
      "Links:\n",
      "\n",
      "* [Natalie's LinkedIn](https://www.linkedin.com/in/nataliekwong/){:target=\"_blank\"}\n",
      "* [Why the Future of ETL Is Not ELT, But EL(T)](https://airbyte.io/blog/why-the-future-of-etl-is-not-elt-but-el){:target=\"_blank\"}\n"
     ]
    }
   ],
   "source": [
    "print(github_data[40].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML parsing error in _podcast/_template.md: while constructing a mapping\n",
      "  in \"<unicode string>\", line 6, column 8\n",
      "found unhashable key\n",
      "  in \"<unicode string>\", line 6, column 9\n"
     ]
    }
   ],
   "source": [
    "import frontmatter\n",
    "import yaml\n",
    "\n",
    "def parse_data(data_raw):\n",
    "    data_parsed = []\n",
    "    for f in data_raw:\n",
    "        try:\n",
    "            # Try standard frontmatter parsing first\n",
    "            post = frontmatter.loads(f.content)\n",
    "            data = post.to_dict()\n",
    "            data['filename'] = f.filename\n",
    "            data_parsed.append(data)\n",
    "        except yaml.constructor.ConstructorError as e:\n",
    "            print(f\"YAML parsing error in {f.filename}: {e}\")\n",
    "            # Fallback: extract content without frontmatter parsing\n",
    "            content_parts = f.content.split('---', 2)\n",
    "            if len(content_parts) >= 3:\n",
    "                # Has frontmatter, extract just the content\n",
    "                content = content_parts[2].strip()\n",
    "            else:\n",
    "                # No frontmatter, use entire content\n",
    "                content = f.content\n",
    "            \n",
    "            data = {\n",
    "                'content': content,\n",
    "                'metadata': {},  # Empty metadata due to parsing error\n",
    "                'filename': f.filename,\n",
    "                'parse_error': str(e)\n",
    "            }\n",
    "            data_parsed.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error parsing {f.filename}: {e}\")\n",
    "            # Create minimal data structure\n",
    "            data = {\n",
    "                'content': f.content,\n",
    "                'metadata': {},\n",
    "                'filename': f.filename,\n",
    "                'parse_error': str(e)\n",
    "            }\n",
    "            data_parsed.append(data)\n",
    "    \n",
    "    return data_parsed\n",
    "\n",
    "parsed_data = parse_data(github_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Standing out as a Data Scientist',\n",
       " 'short': 'Standing out as a Data Scientist',\n",
       " 'guests': ['lukewhipps'],\n",
       " 'image': 'images/podcast/s01e04-standing-out-as-a-data-scientist.jpg',\n",
       " 'season': 1,\n",
       " 'episode': 4,\n",
       " 'ids': {'youtube': 'Sb4CJlonB3c',\n",
       "  'anchor': 'Standing-out-as-a-Data-Scientist---Luke-Whipps-envr7e'},\n",
       " 'links': {'youtube': 'https://www.youtube.com/watch?v=Sb4CJlonB3c',\n",
       "  'anchor': 'https://anchor.fm/datatalksclub/episodes/Standing-out-as-a-Data-Scientist---Luke-Whipps-envr7e',\n",
       "  'spotify': 'https://open.spotify.com/episode/2Yxay9HJmd6dvk34MHJ0K2',\n",
       "  'apple': 'https://podcasts.apple.com/us/podcast/standing-out-as-a-data-scientist-luke-whipps/id1541710331?i=1000502844994'},\n",
       " 'transcript': [{'line': \"Last week, we talked about building data science teams, and recruiting data scientists. Today the topic is slightly different. We'll talk about the recruitment process, but from the candidate’s point of view. We have a special guest today, Luke. You probably know Luke as a podcast host. Usually you hear Luke asking questions. But today the situation is different. Luke takes the guest seat. Luke is not only a podcast host, he is also a recruiter. He's a co-founder of Neural AI, which is a company that specializes in recruiting AI specialists, data scientists, machine learning engineers, and others. Today, Luke will share his experience with us and tell us how data scientists and other data professionals can stand out during the recruitment process. Hi, Luke. Welcome.\",\n",
       "   'sec': 99,\n",
       "   'time': '1:39',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Hi. Thanks for inviting me on the show, Alexey. This feels very weird being on the other side of the fence now.',\n",
       "   'sec': 149,\n",
       "   'time': '2:29',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Luke’s career and the story of Neural AI'},\n",
       "  {'line': \"Thanks for coming. So, Luke, let's start with your background. Can you tell us how you started your career? How you got into AI and how it led to co-founding your own recruitment company?\",\n",
       "   'sec': 160,\n",
       "   'time': '2:40',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Thanks for inviting me on the show Alexey. Hi to everyone who's joined. As Alexey said, my name is Luke, and I'm the co-founder of Neural AI. I've been recruiting in the data analytics space for probably close to 10 years now. That started in the traditional BI and analytic space. Naturally, as things became more prevalent in the industry, like advanced analytics, and data science and machine learning and deep learning, my career transitioned with it. Most people in recruitment — 99% — fell into it. Then most people fall out of love with it. But I've stuck it out for 10 years now.\",\n",
       "   'sec': 177,\n",
       "   'time': '2:57',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Neural came around from a couple of different perspectives. One of those perspectives was… I was just about to turn 30. I had two choices that I could have made. I could either continue working for businesses that I have to become a part of and embrace their values and embrace their processes and the way that they work, or… I build something that represents what I believe, what I feel about how recruitment should be done.',\n",
       "   'sec': 223,\n",
       "   'time': '3:43',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Naturally, I went for the second option, and that led us to found Neural. There's a general consensus about what the recruitment industry is. I really wanted to create a business that counterbalanced the bad reputation that a lot of recruitment consultants have. I wanted to create a business that A) is built on the foundation of providing value to the actual community that we recruit for, and B) try and live by something that makes deposits into that industry, not just withdrawals. So, as Alexey said, I run a podcast and I'm looking into running AI events, like seminars, to what this is. Ultimately, I wanted to create more of a community effort rather than, “Hey, we've got jobs, you've got candidates,” or vice versa, “You've got a CV, we've got some jobs.” I think that's very, very old school and very transactional.\",\n",
       "   'sec': 256,\n",
       "   'time': '4:16',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"For me, as I say Neural was built on the back of wanting to create something different that is value and community driven, rather than just, “Hey, do you want to work on a new business?” So yeah, we started in early 2020. So probably not the best time to start a business in the bits of a global pandemic, but the value proposition that we've got and the specialism in data, and artificial intelligence has really hit the mark. That's a bit about me and a bit about my background. I hope that gives you a good snapshot.\",\n",
       "   'sec': 316,\n",
       "   'time': '5:16',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Yeah. Indeed, what you said about the bad reputation of recruiters – I think everyone can agree to that. Sometimes they just come out of nowhere, callin... but I can tell you that Luke is different from this. And this is really great — what you're doing, like all these podcasts and events – that is really awesome. It's not just a cold call out of nowhere, but actually like a community around that. That's really great and thank you Luke for doing that.\",\n",
       "   'sec': 352,\n",
       "   'time': '5:52',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Yeah.', 'sec': 387, 'time': '6:27', 'who': 'Luke'},\n",
       "  {'header': 'Steps in closing a data science position'},\n",
       "  {'line': \"Coming back to your main work as a recruiter – in data science, maybe – I don't know if it's different from usual developer positions, or maybe analysts. But I know that there are not so many good candidates… typically, it's quite difficult to close positions. So, what does it involve to close a position? What are the typical steps? How do you go around that?\",\n",
       "   'sec': 388,\n",
       "   'time': '6:28',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"It is definitely more difficult than your average kind of development role because – you've probably experienced this as well — if you speak to 100 different people, or 100 different businesses and say, “What is a data scientist?” – you're probably going to get 100 different answers. One of the big challenges for us is – every single position that we work on, is quite different from the last. Every single business that we work with has a definition of what a machine learning engineer does, or what a data scientist does, or what X, Y and Z does.\",\n",
       "   'sec': 422,\n",
       "   'time': '7:02',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"One of the big problems – or the big challenges of the work that we do is – that every single company is different. That in itself is a challenge, because you need to first understand the problems and the different challenges that those individual businesses are facing and it's difficult to group stuff together when everyone's got a different perspective on stuff. I can't remember the last time I worked on an easy position. Now, I don't think there's such a thing in the data science and AI community, especially at the senior level. But for me, I think our process breaks down into… to just give you a real quick bullet point for what we do.\",\n",
       "   'sec': 455,\n",
       "   'time': '7:35',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"It breaks down into six key areas. Number one is role definition. Typically, we'll work with businesses to help them define the actual conditions within the business. A lot of companies still struggle with that, because it's still such a new, undefined market. We help companies define the actual positions that they're looking for, and offer guidance in terms of what's achievable.\",\n",
       "   'sec': 495,\n",
       "   'time': '8:15',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Secondly, we are heavily network-focused in terms of the candidates that we typically provide. As a business, we don't advertise. We do a little bit, but that's not our main source of candidate attraction. For us, the second point is we would market map the talent pools of people that they're potentially looking for – both from our network and from a headhunting perspective. So essentially, it'd be the people that we know and the people that we don't know.\",\n",
       "   'sec': 522,\n",
       "   'time': '8:42',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Thirdly, we would put together a long and short list. The long list are the people that we think could be okay for the role or have quite a lot of crossover. The shortlist of the people that we spoke to, that we know are right for that position. We then deliver the CV and put it into the business.',\n",
       "   'sec': 554,\n",
       "   'time': '9:14',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Following that we would manage that process of recruitment. You've got to think of us as your interview buddy. That's probably a really bad way to describe it. But we manage the process from end-to-end, both from a client and candidate perspective. So an interview preparation feedback, we deliver that. We help you prepare. We highlight concerns or positives in the process. If there are problems or challenges, we tend to bring that to the table, and we will try and overcome them with both candidate and client.\",\n",
       "   'sec': 575,\n",
       "   'time': '9:35',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Lastly, when we get to that stage, we manage the closing of the process, both from an offer negotiation perspective, but also from resignation, and any kind of problems that come up in the process. So, we're not a traditional recruitment company, we do everything. The clients work with us on a singular position or two or three positions, but they'll be on an exclusive basis. We will be essentially an extension of that company that we're working with. And that means we run the process in full – from end to end.\",\n",
       "   'sec': 611,\n",
       "   'time': '10:11',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Usually, how many candidates do you speak with? How wide is the funnel? How many people do you have on this shortlist? And how many do people you talk to… you get on the phone? To close one position?',\n",
       "   'sec': 663,\n",
       "   'time': '11:03',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"It's different from position to position. Because we work in those kinds of singular positions. Some roles that we work on could be in the hundreds. There's a role that I'm working on at the moment where I'm doing a European-wide search, and I've long-listed probably about 25 candidates across the whole of Europe. It's really, really vast from… 10 to 20 candidates up to 200-300 candidates, depending on the type of position.\",\n",
       "   'sec': 683,\n",
       "   'time': '11:23',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"As I mentioned this earlier, we don't actively advertise. We don't advertise lots of positions and stuff. So we don't deal with the volume of candidates that you guys at OLX have. To give an example – one of my clients in Munich, for one position, for an AI engineer – they've received like 1300 CVs. We would never look at that amount of CVs. So we're not volume. On average, we probably look between 10 and 20 CVs a day, something like that. That's across all positions that we're working on.\",\n",
       "   'sec': 719,\n",
       "   'time': '11:59',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Well 10-20 CVs per day, still quite a few CVs to look at.',\n",
       "   'sec': 767,\n",
       "   'time': '12:47',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Yeah.', 'sec': 774, 'time': '12:54', 'who': 'Luke'},\n",
       "  {'line': \"It’s not the volume that we our recruiters have to deal with – but it's still quite a lot of CVs that you need to look at every day.\",\n",
       "   'sec': 775,\n",
       "   'time': '12:55',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"90-95% of the people that we work with – we are approaching. It might not necessarily just be a CV, but it might be: set up conversations with people on LinkedIn and stuff like that. So I'd say “profiles” in general – probably between 10 and 20. But that might be going through someone's LinkedIn or an actual profile or X, Y, Z.\",\n",
       "   'sec': 786,\n",
       "   'time': '13:06',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Getting recruiter’s attention'},\n",
       "  {'line': \"In these 10-20 profiles, what does usually get your attention? What do you look at typically? When you say, “Okay, I really have to call this candidate.” Versus “Okay, I'm not sure. Maybe I'll talk to this person later when I first deal with these other candidates.”\",\n",
       "   'sec': 817,\n",
       "   'time': '13:37',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"When we spoke about this before, I tried to look back at some of the old CVs that I've been like, “Yes, they look amazing!” And I will try and substantiate all of these points. So it makes it really easily understandable. I start from the kind of ‘first opening’ of a CV… As a disclaimer for anyone who's listening right now – this is one person's view, and it's very subjective.\",\n",
       "   'sec': 847,\n",
       "   'time': '14:07',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I'm a bit of a sucker for good design from an artistic perspective. This is something that your reader will see before they start reading your CV. So I try and live by something – which is: your interview starts as soon as they open your CV, and before they start reading your CV. The first thing that they see is how well-designed your CV actually is. So I always comment when I can clearly see that someone has taken the time to format and design their CV in a way that is really attractive.\",\n",
       "   'sec': 876,\n",
       "   'time': '14:36',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"This is the representation of you. If I open a CV, and it looks great – I'm instantly interested about what's on the CV. Whereas, if I open a CV and think “Hmm… that looks pretty awful,” it sets a negative tone before someone's even started reading. From my perspective, I think design is a really big part of that.\",\n",
       "   'sec': 916,\n",
       "   'time': '15:16',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"If we're talking about content specifically… for me, it breaks down into three key areas that I look for, and try and tick boxes in my own head. Again – this is a disclaimer – but businesses pay us to find specific people, so we're probably a lot more critical on the profiles that we're looking at. There's definitely a difference between being an internal talent acquisition and the headhunter.\",\n",
       "   'sec': 940,\n",
       "   'time': '15:40',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Number one is, I’ll instantly look for the crossover between the business and the role that they're applying for with the company that they're currently working in. The reason I say that is not because it's a name game, or… It's not because it's all about the business that you work for. But it's primarily to do with the industry challenges that that business is facing, and how well would you be able to actually understand those industry challenges.\",\n",
       "   'sec': 975,\n",
       "   'time': '16:15',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"For example, if you're a data scientist at Audi, and you're applying for a data science position at BMW, and you're instantly recognized more, because you should understand the industry that you're working in, and the conversation that you can have internally with the business that you're applying for will be a lot higher than someone who doesn't understand that industry. Again, this is not a name game. But it definitely does add value to your CV. When I say, “Right, I'm looking for someone like BMW, or Zalando, or Adidas, or an autonomous driving startup.” The first thing that I see is that you're working in a very, very similar business. That's point one.\",\n",
       "   'sec': 1005,\n",
       "   'time': '16:45',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Point number two is… It's not just all about that business – It's mainly to do with the use-cases and the actual projects that you're working on right now. I tend to look for how close or how far you are away from the actual use cases and problems that you're going to be working on. Because the clients that we typically work with – they come to us with specific roles, working on specific things. So my first thing is — how close are you from a business perspective? Secondly, how close are you from a use-case perspective? And how much crossover is actually there across those two things? If those two things aren't there – it's actually really difficult… Maybe other headhunters have got a different spin on this, but for me – I think that culturally, you could be great from an alignment perspective, and you probably could be good for that business, but from a headhunting perspective… If we were working together right now, Alexey, and you said to me, “Hey, I need this, this, this, this and this,” and the profile that I gave to you in response to that, didn't have any of that, but I said, “but you’ll really like this person, and culturally, they'll fit in.” Your feedback would be, “That's not what we're looking for.” So again, those are the first two things.\",\n",
       "   'sec': 1050,\n",
       "   'time': '17:30',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Lastly, I do look for that kind of cultural and industry alignment. This isn't typically the business per se, but it's the type of business that you're working for. If you're working for a huge global financial services business, and you're applying for a 10-man startup company, there are going to be some huge, cultural differences between those two businesses. And for me, I'm like, “Are they gonna get that industry?” And vice versa. If you've had a start-up career, are you going to get working in a big financial services industry? 9 times out of 10, there's so much difference between those industries or businesses that it usually doesn't work.\",\n",
       "   'sec': 1136,\n",
       "   'time': '18:56',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"That's the first thing that I look for… and that's the first thing that kind of pops up. But on top of that... One of the things that really gets me about CVs... Sometimes I'll open a profile, and their tech stack overview, and they – their profile, not their projects – looks amazing, right? And they've got every tech on there, every programming language, TensorFlow, PyTorch – all different use cases. But when I actually look at the projects that they've been working on, those two things are not linked. So it's just buzzword bingo on their CV, but the actual projects — things that are actually done — don't link to that. For me, the second point is – and this is really obvious, but – your projects are related to the tech stack that you’ve got there. You'll be surprised about how many profiles don't do that. Your CV should be a representation of what you're doing. If you claim to know, X, Y, and Z, you should be able to back that up with specific examples of projects and be able to illustrate that in your CV.\",\n",
       "   'sec': 1190,\n",
       "   'time': '19:50',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Just to clarify – by your projects, you mean, not necessarily projects on GitHub – but a list of projects that this person has done previously, right?',\n",
       "   'sec': 1260,\n",
       "   'time': '21:00',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Yeah. I think it's both. It depends on what level you're coming in… This is the difficult thing, it's all very singular. That might be the case for one person, but there might be a more junior candidate trying to make or break into the industry. Then I would want to see what GitHub projects or personal projects you've worked on, which would illustrate that technical experience and that understanding.\",\n",
       "   'sec': 1276,\n",
       "   'time': '21:16',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"But if you're more senior… if you tell me that you know X – you've got to show me where you've done that, or how you've used that. So the second main point is that I would want to see that the projects that you've worked on are a representation of the tech stack that you think that you understand.\",\n",
       "   'sec': 1303,\n",
       "   'time': '21:43',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Lastly, this breaks down into three key categories, which is tenure, common themes and growth. If I look at CV, I would want to see that someone had had a good amount of time in the businesses that they've worked in, and not jumped from place to place for an extra 5K K, or just a new change of scenery. As a headhunter, I think, “are you someone who's going to carefully choose the right industry and the right opportunity for you – but are you actually gonna stay there?”\",\n",
       "   'sec': 1328,\n",
       "   'time': '22:08',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"And then secondly, the common themes and growth, it's — have you got a purpose in terms of your career right now? Have you done a huge amount of broad projects? And you go from one data science job to another? Or you are like “I'm really interested in this sector, or industry, or type of clients, and that's where I'm really going.” And growth. I would want to see some progress in their career. If you're a data scientist now, but you were a data scientist five years ago – my first question would be why haven't you progressed? Run me through that. I know, there's gonna be some examples of people that just want to do that one particular position. But I would want to understand those kinds of points. So that's what I typically look for. Sorry if I just threw loads of information out there.\",\n",
       "   'sec': 1368,\n",
       "   'time': '22:48',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Let me summarize what you said and then you tell me if I got it right. So first, you look at the design — it shouldn't be completely bad and faceless. Just a bit of creativity will not hurt your CV — to get your attention. Then you look at the industry, where the candidate works. It should be as close as possible to the industry of your client. It also involves cultural fit… If your position is in a startup, then the ideal candidate will have experience working at a startup, right?\",\n",
       "   'sec': 1421,\n",
       "   'time': '23:41',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Right', 'sec': 1469, 'time': '24:29', 'who': 'Luke'},\n",
       "  {'header': 'Project portfolio'},\n",
       "  {'line': \"Then you also look at projects. What is important in projects? Is that they are linked to actual skills. So it's not just a bunch of buzzwords on CV, but actually, for each project – it's clear for you how these skills were used. Finally, you look at people who don't jump too often from position to position. Who have focus. And also you look at career progression. Did I get it right?\",\n",
       "   'sec': 1470,\n",
       "   'time': '24:30',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Yeah. Just on the use-cases... For me – you can work on recommendation systems in Spotify, or GetYourGuide and then also work on recommendation systems in Zalando. It's about finding balance between understanding those kinds of industries and understanding the use-cases that those industries would typically work on. The thing with data science – it's about understanding the business problem, to be able to apply your skills to solve those problems.\",\n",
       "   'sec': 1504,\n",
       "   'time': '25:04',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"So for me, it's a combination between thinking, “right, do you know the industry?” and “do you know the use cases?” Or — do you know the industry, but might have slightly different use cases? Or — do you know the use cases, but might have a slightly different industry? If it's one of those things where you've got to look at it and balance and think, “well what do they know?” and “where can we make this work?” So it's really different from candidate to candidate. And again, it's super subjective and very singular. But that's typically the stuff that I’ll look for.\",\n",
       "   'sec': 1541,\n",
       "   'time': '25:41',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"From what I understood, the important thing is to make it clear on your CV what are the use cases you worked on. Then, when the recruiter – like you – looks at the CV, it's immediately clear for them: “Okay. These are things that the candidate worked on, these are the projects.”. These use cases, these are the industries. Then for you, it's immediately clear, “Okay, this candidate is a good fit.” Or “Maybe this candidate is not necessarily a good fit,” right?\",\n",
       "   'sec': 1575,\n",
       "   'time': '26:15',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Yeah, sure.', 'sec': 1604, 'time': '26:44', 'who': 'Luke'},\n",
       "  {'header': 'CV design and structure'},\n",
       "  {'line': \"I also wanted to ask you about design. Usually data scientists are not designers. We don't spend a lot of time using tools like Canva, or Adobe Illustrator, or whatever to come up with an excellent CV, like designers would do. I wanted to ask you what is it that you look in design? How does a good design look to you?\",\n",
       "   'sec': 1604,\n",
       "   'time': '26:44',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Yeah. I'm not saying that this has to be super colorful. What I am saying is – it needs to be clear. It just needs to look professionally clear. I know it's not a very good way to describe it, but some CVs I open and it's clear that there's been no thought in terms of how to put that together. “This is everything I've done – let's just throw that on to a word processor and let's just send out.”\",\n",
       "   'sec': 1639,\n",
       "   'time': '27:19',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Design is subjective. I also think it's very dependent on what kind of business you're applying for. If you're applying to an Allianz or a Munich Re – would I advise having a really colorful, cool, techie CV? No. I'd say you need to make that look professional. To capture the audience that you're talking to. Because the moment someone opens your CV, they are judging who you are. If you don't fit the mood of the type of business that you're applying to – be that startup or financial services or whatever – then in that first couple of seconds, it needs to hit home with that individual business.\",\n",
       "   'sec': 1685,\n",
       "   'time': '28:05',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"They need to think – I think it's more of a psychological thing – but they need to think, “that's the type of view of us as a business.” So the question that you need to ask yourself is “what are you trying to portray to the people that you're trying to network with?” Is it ultra-professional banking, insurance, corporate? Which is fine… If you wanted to go that route, then double down there. Or… do you want to work with cool techie startups -- what's their vibe in that community? You need to replicate that with the profile that you've built. I hope that gives you a little bit more color around the design part.\",\n",
       "   'sec': 1729,\n",
       "   'time': '28:49',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"So it’s not only about how you choose colors, but also how you structure it. So it's not just a brain dump, right? When you just sit down and list all the skills, all the technologies you ever worked with, all the places of work. Instead of giving a brain dump — you structure it. So it makes it easy for the receiver of this information to actually go through this and understand this information, right? It's not about colors. It's not about these beautiful shapes.\",\n",
       "   'sec': 1771,\n",
       "   'time': '29:31',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Yeah, exactly.', 'sec': 1803, 'time': '30:03', 'who': 'Luke'},\n",
       "  {'header': 'Changing jobs too often'},\n",
       "  {'line': 'We have a question. How often is too often when changing jobs? What is currently the average time that the person stays in a job? What would be a red flag for you?',\n",
       "   'sec': 1810,\n",
       "   'time': '30:10',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Anything under a year is a red flag. And a year to two years in most companies is about average now. And anything over a two year period — that's a good amount of time to spend in a company right now. But it's not necessarily about one thing that happens. Everyone can make mistakes. I've done it in the past: you join a business, it doesn't turn out to be what you think it is. That's totally fine. But if that's a common theme across the experience you've got — if you've had 12 roles in 12 years, and they've been on average, a year each, that says to me that you, you don't like sticking in one place.\",\n",
       "   'sec': 1826,\n",
       "   'time': '30:26',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"As a headhunter, that is concerning. Because the companies that we work with, they want us to find people that are going to stay in the business, progress, all of that sort of stuff. So I'd say it's more about the consistency of how often you're moving. If you have a really solid career, and it was two, three years at most of the positions you had, but one position — your last position — was three or four months – didn't work out – totally cool. But if it's replicated across every role you've worked in, that that's a concern.\",\n",
       "   'sec': 1880,\n",
       "   'time': '31:20',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Standing out as a fresher / junior candidate'},\n",
       "  {'line': \"I understand. You mentioned that you look for a background in a specific industry. But what about freshers who don't have any background? Do you also work with junior candidates? If you do, what do you look for in junior candidates?\",\n",
       "   'sec': 1919,\n",
       "   'time': '31:59',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"I do work a bit with more junior candidates, but I wouldn't say that's my key focus. The key for me when I look for junior candidates – any candidate actually – is having purpose in their search. I know that sounds a bit fluffy. But there are lots of candidates.\",\n",
       "   'sec': 1942,\n",
       "   'time': '32:22',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"When I open their CV, it literally looks super generic. Generic tech stack, generic kind of overview, generic backgrounds. Apply for anything, no direction in terms of where they want to take their career. My thoughts on this is, if you're trying to break into the industry, it's really difficult to go broad. You'll be most successful if you pick something — you pick an industry, or if you pick an area of data science or machine learning that you're really passionate about, and double down on that. Taking autonomous driving, as an example.\",\n",
       "   'sec': 1978,\n",
       "   'time': '32:58',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"If you're passionate about the industry, then do things that illustrate that. Which would bolster your profile and elevate you above the people that are generic. As a human being I try and live by “aim small, miss small”. For me, I pick an industry and think — what can I do alongside the technical skills and the experience I'm trying to gain? What can I do outside of all of that? If someone opens my profile, even though you're a junior, or you're a fresher, they look at you and think you're probably not there in seniority, but you definitely want to do this, like this is 100% what you want to do.\",\n",
       "   'sec': 2026,\n",
       "   'time': '33:46',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I'd start going to tech meetups and start going to conferences and start learning about the industry and start learning about it from a commercial business perspective. And all of this I would highlight in your profile. When someone opens it, it's not just “Okay, cool. They know TensorFlow, and they know Python and they know X,” which pretty much everyone knows. You're setting yourself aside from the generic, “do anything” candidate. If you're a junior, and you're trying to break into an industry, find one or two industries that you're really, really interested in and bolster your profile around that industry, because that will give you a better chance of entering that industry.\",\n",
       "   'sec': 2068,\n",
       "   'time': '34:28',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"As you said, one of the first things you look at is the match between what your client is looking for and what is on the CV. Then for you, if it's clear what the focus of the candidate is, even if it's a junior candidate, then the candidate already stands out from the rest of the candidates, right? Because it's clear that this person really wants to work in this area, which also happens to be the area of your client, right?\",\n",
       "   'sec': 2116,\n",
       "   'time': '35:16',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Exactly. For me… When people are clearly passionate about something – maybe I look at this from a human perspective – but I want to try and help that person because they clearly want to do this. So for me, I ask any of the clients that I've worked with, there have always been an instance where I'll be like, “Hey, Alexey, I know, this guy is too junior, but trust me on this, this is the type of person that in a year or two years time will be an absolute superstar.”\",\n",
       "   'sec': 2150,\n",
       "   'time': '35:50',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I don't think you get as many opportunities to do that as a candidate — to get those opportunities for someone to represent you in this way if you approach the market in a really generic way. When you’re just like, “I will do anything,” like, spray and pray. You want people to believe in you. That is getting super cheesy, but when I see someone that clearly wants to do something, I'll go out of my way to try and help that person. I think, “this person in a couple of years will be amazing.” So I'm trying my hardest to help that person do that. So even at a junior level, I'll still look for “what are you doing outside of your masters, or are what you're doing outside of your internships that promote your profile in the industry, or focus that you want to move into?”\",\n",
       "   'sec': 2182,\n",
       "   'time': '36:22',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Tailoring your application to the position'},\n",
       "  {'line': \"So if you really want to tailor your application to a specific position, you need to show that you really focus on this industry – you really like this industry. But is there anything else candidates can do to show that they are really interested in this particular position? Let's say somebody is applying to a position online and they want to make sure they get this position? What are the things they can do for that?\",\n",
       "   'sec': 2237,\n",
       "   'time': '37:17',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"So I'll give you my PC – what’s the right way to do it – and then I would give you what I would personally do. Most companies will probably hate me for saying this. So number one… This is simple and probably some of your listeners are rolling their eyes now. But you absolutely need to read the job descriptions before you apply. I know that sounds really stupid and super simple BUT when you're tailoring your application, you're not doing that to understand what they're looking for. You're doing that so you can apply your skills and outline how you can help them solve those problems.\",\n",
       "   'sec': 2274,\n",
       "   'time': '37:54',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"As a candidate, you absolutely need to do some research before you apply to a business. If you're blanket-sending out your application, there are companies that are getting 1300 or more applications for a role. So you've got two options. You can either throw your hat into that and hopefully something happens. OR you can think, “as a business, what are the problems that this company is facing right now? What are their challenges? How does my experience and what I've done as an individual – how does that link to that?” And “How can you make the distinction between those two things?” So how do you start — how point A goes to point B? “This is how those two things are linked.”\",\n",
       "   'sec': 2325,\n",
       "   'time': '38:45',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"It's not just about the industry or the use cases specifically, it's about how you can link those two things together. First, I try to outline the challenges and problems that that individual company is facing. Secondly, I would put together an email, LinkedIn – however you want to do it – but make it ultra-targeted. And make it super relevant for the reader. So when that message lands with someone, you want to take as much of the work off of their plate as possible. Instead of them having to click into your CV and then try and find that information, I would be like, “Right, this is a challenge that you guys are facing right now, this is what I've done that solves that challenge. Challenge B, this is what I've done. Challenge C, this is what I've done.”\",\n",
       "   'sec': 2381,\n",
       "   'time': '39:41',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"The more you can tailor that and make it very, very specific for that application, the more someone is going to open that and think “Shit, this guy or girl has really taken the time to A) do their research and B) it looks like they know what we're trying to do here.” Make it ultra, ultra targeted.\",\n",
       "   'sec': 2442,\n",
       "   'time': '40:42',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Thirdly, I would highlight that in your CV. You open their CV, and it doesn't reflect what you're saying in that email. So you need to adjust your CV based on the conversations that you're trying to have with the clients that you're approaching, because that's a representation of your skills and what you've done in the past. If it doesn't link to that, they're gonna say, “Okay, cool, you sent a great email, but actually what are you doing in your experience?”\",\n",
       "   'sec': 2466,\n",
       "   'time': '41:06',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Lastly, you need to research and approach the right people in the business. Companies will hate me for saying this. I'm not a big fan of throwing my hat into 1000 applications. That's not personally the way that I would do it. If I was going to try and approach a business, I would find the right people that I wanted to talk to. And I would approach them directly. But I wouldn't do it in a blanket way, that's just gonna piss people off. Because people know if you've taken the time to approach them with something valuable that's targeted – if you do that, you'll have a really great impression with that business. If you do it in a blanket way, a lot of the time it will be disregarded, and it will just piss people off. So my thing is – if you're going to approach people directly, which I would. Firstly, I would do it in a really targeted way that that person will know that you've taken the time to do that.\",\n",
       "   'sec': 2508,\n",
       "   'time': '41:48',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Is everyone gonna respond to you? Probably not. But the people that do and the people that appreciate that sort of stuff will. They’ll be a sponsor for you into the business. To give you an example, a friend of mine recently moved out of recruitment into a software sales job. The way that he approached it — he filmed himself, giving an overview of him as a human being and what he does and his experience and the value that you can bring to organizations. He reached out to sales directors within big software vendors, like Domo, Salesforce – companies like that. And, and he was like, “Look, this is what do and this is why I'd love to work for you guys.” It's all super targeted. So as the hiring managers opened all of these video-CVs, they were like, “This guy's taking the time to do this.” And he had multiple companies come back to him and say, “We've not seen anything like that before. Thank you for taking the time to do that.” And he landed one of the jobs with one of those companies. And now that company uses his approach with the sales tactics that they have.\",\n",
       "   'sec': 2581,\n",
       "   'time': '43:01',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"It's just an example that – if you're going to approach people directly, and do that, make it so targeted. So when it lands with them, they can see you've put the time and effort into doing that.\",\n",
       "   'sec': 2655,\n",
       "   'time': '44:15',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Then you really need to focus on a few positions, because there is no way you can do that for 10 on 20 positions – that’s just too much time. You really need to pick an area where you want to focus and then find the companies that you really want to work with, and then approach everyone individually. Right?',\n",
       "   'sec': 2666,\n",
       "   'time': '44:26',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Yeah, this links back on to having purpose in your career. If you can segment your purpose and say… Let’s take autonomous driving, for example. It's easy to break down all of the autonomous driving businesses in Germany. If you look at a machine learning engineer – how are you going to approach that? There's 4000 jobs in Germany right now. Where do you start with that? If you say, I'm looking for AD startups in the autonomous drive space in Berlin. That's an easily digestible way that you can say, “This is what I'm going to try and do. And this is the industry and the kind of landscape that I’m trying to do it in.” Everything needs to feed into one another.\",\n",
       "   'sec': 2690,\n",
       "   'time': '44:50',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Going from academia to industry'},\n",
       "  {'line': \"We have a couple of questions on Slido. If somebody wants to change their career, from academia to industry, what can they do? How can they stand out? How can they compete with people who already have experience in industry? Usually, when you're hiring somebody, you already want to have somebody with experience. How can these people – who just graduated, got a PhD or worked in academia – how can they make this transition? Do you have any recommendations for them?\",\n",
       "   'sec': 2742,\n",
       "   'time': '45:42',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"That's something that people struggle with constantly. I think the biggest challenge that I find is that companies push back. The clients that I've worked with – they push back on the fact that the people are coming from those research and academic positions. They don't have the product mindset. I'm speaking pretty broadly here and drawing everyone with the same brush, but… a lot of the time, they have a “research for research” mindset.\",\n",
       "   'sec': 2785,\n",
       "   'time': '46:25',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"They don't have that “commercial-business” mindset. Not from a business strategic perspective. They don't have that “We need to make shit happen. And we need to actually do something, rather than just research. And we have all the time in the world”. It comes down to that different mindset shift of moving out of “Cool. We're doing academic research now. And we really want to find cool answers. And we really want to do it for the research sake,” — which is also extremely valuable — to actually “we're building this product to sell.” Because any business that's not researching, they're there to make money. It's the difference in mindset between academic research to, “we're here to actually build a product to sell to people.”\",\n",
       "   'sec': 2839,\n",
       "   'time': '47:19',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"The mindset is the biggest change, or the biggest challenge you would need to make and would help you transition out of that. That internal narrative that you have about what you do, you need to switch that from that piece to that piece. I can definitely help you with that. If you want to connect to me on LinkedIn, I can talk you through that in more detail. Secondly, if you've got an opportunity to do something internally at an academic institute – to productionize something – do it. Then you've got experience in actually productizing something. There are people that I've worked with in the past that have done that in small terms. So it's not just all research. On top of that, I would start looking at personal projects about what you can do in the background to add on top of the research you're doing.\",\n",
       "   'sec': 2895,\n",
       "   'time': '48:15',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I would think, “Right, well, what am I researching? How can I apply that in a real world scenario?” And do a personal project on it. That shows me commitment. Because I say, “Look, I know that I hadn't had the production level experience. This is what I've done to counteract that.” When you send your profile to someone, you need to highlight the connection between those two things. So the easiest thing you would do is understand the mindset of the businesses that you're trying to apply for. And secondly, start working on personal projects that would complement the research work that you've been doing,\",\n",
       "   'sec': 2954,\n",
       "   'time': '49:14',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Working just for money — is it bad?'},\n",
       "  {'line': \"Or find a project at university. Some universities collaborate with companies – with the industry – and I think it's a really good idea to try to get in these projects and learn from that. We have another question. Are there people that are really passionate about positions in advertising or marketing? Why does wanting a job for money make you a bad fit? That’s actually two questions.\",\n",
       "   'sec': 2994,\n",
       "   'time': '49:54',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Maybe. The people that I've seen really accelerate their career quickly and to high levels are the people that have real key focus. There's nothing wrong with taking a job and focusing purely on the financial part. If that's your focus, and that's your goal, go for it. Go and work for McKinsey and work 90 hours a week. That's where you can earn the most amount of money. I don't think there's anything necessarily wrong with doing that, and just taking the job for financial benefits.\",\n",
       "   'sec': 3039,\n",
       "   'time': '50:39',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"But it's all subjective. It depends on you as a human. I'm looking at the people that I've seen be really successful and the profiles that I see and think “Shit they're brilliant”. It’s because they've got key focus. Even if that is marketing, there are going to be companies out there, that will be like, “Great. That's exactly what we need.” It's not necessarily all about the industry, per se. It's about having your focus in terms of what you want to do. If that's financial – that's financial. If it's “I want to progress my career,” the quickest way to do that is by having a focus – be that in that industry or that area. Does that answer your question? I hope it did.\",\n",
       "   'sec': 3080,\n",
       "   'time': '51:20',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'I have a follow up question for that. What is your opinion on people who – you reach out to them and the first thing they ask is, “Hey, but what is the salary?” Is it a red flag for you? Or is it a normal thing? How do you react to that?',\n",
       "   'sec': 3126,\n",
       "   'time': '52:06',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"I totally empathize with everyone that works in this industry. They're contacted every single day by hundreds of recruiters with shit roles, paying shit salaries. I think it's fair play – do you want to waste your time having a conversation with someone if, number one, they can't pay the money that you need? So for me, it's never a red flag, because I appreciate how frustrating it must be from their side. If the sole focus on their new job search is financial, that is a bit of a red flag to me personally, because you're going to go where the money is. If another company is paying more money than the clients that I'm working with – that's a big concern.\",\n",
       "   'sec': 3142,\n",
       "   'time': '52:22',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"There's a lot of debate in the recruitment world, about how much information you should share in the first approach. I'm on the side of — I'll give you the job specs, the client name, salaries, whatever you need to be able to make an accurate decision on – should we have a conversation? I'll give you that information. Because I don't think you can tell being an honest business if someone asks you a question, and you don't answer it. So for me, it's not a red flag. I think that stems from a lot of wasted time by shit recruiters.\",\n",
       "   'sec': 3193,\n",
       "   'time': '53:13',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"90% of recruiters, in my experience, when I ask them “Hey, what is the company?” — they don't answer. So what you're doing is clearly different from the rest of external recruiters. I really appreciate that.\",\n",
       "   'sec': 3234,\n",
       "   'time': '53:54',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"The only reason why they do that — this just highlights how bad in industry recruitment can be sometimes – is that people will put together fake profiles of fake candidates and to extract leads from recruiters that will share that information. In my career, I don't think I've ever – not once – had a candidate and they also say “Oh, well you can also apply directly for the business and cut me out of it” kind of thing. In my career, I've never ever had that. So that's never ever been a situation that I've experienced.\",\n",
       "   'sec': 3252,\n",
       "   'time': '54:12',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Different CV styles and CV in Germany'},\n",
       "  {'line': \"We also have a question from Castella about CV styles. She grew up in Germany and lives in the US and she sees that the styles of CVs are different. Are the CVs that you're getting vastly different? Or most of them follow the same structure?\",\n",
       "   'sec': 3290,\n",
       "   'time': '54:50',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Germany's got a very distinct style in terms of the classical profile. There's a lot of that. The ones that really stand out for me are the ones that are unique. They take the time to think, “actually, this is a representation of me.” There have definitely been times in the past where someone says, “Oh, what do you think about this? Because this is how you should do it in Germany”. And I'm saying, “Why? Who are the people that are managing the German CV format?” I think it should be a personal representation of you. It should be a personal thing. So yes, and there is, but I would definitely go against it.\",\n",
       "   'sec': 3316,\n",
       "   'time': '55:16',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I have a related question. Because in the States, every blog post that you read, they say, your CV has to be one page long. One page for 10 years of experience. In Germany, I've seen CVs that are five pages long, six pages long. I also saw a 10 pages long CV. What is your opinion?  How long should a CV be?\",\n",
       "   'sec': 3371,\n",
       "   'time': '56:11',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"I think the ideal length is two pages. I don't think you can get enough content on one page to make it sing. Three pages is borderline too much. But two pages is ideal. That's the balance between having enough deep content that will give me context to what you do, but also limit you in terms of “War and Peace.” Two pages is the ideal number. But if you can keep someone's attention for five pages, then – awesome. But 9 times out of 10, there's a lot of content in there that's irrelevant, and it's overload. So two pages are the dream.\",\n",
       "   'sec': 3407,\n",
       "   'time': '56:47',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"So it keeps you focused, but also doesn't let you brain-dump everything.\",\n",
       "   'sec': 3463,\n",
       "   'time': '57:43',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Yeah.', 'sec': 3468, 'time': '57:48', 'who': 'Luke'},\n",
       "  {'header': 'Job titles in the CV'},\n",
       "  {'line': \"We have four more questions. Nishant is asking, “Is it okay to write a job title in CV that more closely represents the work they're doing instead of putting the official title?” From my experience, some companies put “manager” in the role. Like “Analytics Manager” and that person doesn't manage any other people. Is it okay if these people, instead of putting an “Analytics Manager” put “Data Analyst” on their CV? It's not the official title that they have, but it follows the industry trends rather than a particular job description in the company?\",\n",
       "   'sec': 3477,\n",
       "   'time': '57:57',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"I think it is, as long as you're not lying about what you're doing. Is it okay to write “Software Engineer” if your job title is “Software Developer”? I think that's okay. Is it okay to write “Lead software engineer” if you're a junior? That's not okay. It's okay to align it, as long as it is not so far past reality that it could be considered a lie. If you are doing those things, but your job title was slightly off, and you're applying for a data science position, and your job title is… something that isn't that, then for me, it's okay to slightly adjust it to hit the mark. But not at the extent of lying. I don't think you should ever lie on CV, but I do think you should align on your CV.\",\n",
       "   'sec': 3531,\n",
       "   'time': '58:51',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Switching from web development to machine learning'},\n",
       "  {'line': 'If previous commercial experience in a field is loosely related to data science or machine learning, is it an advantage or drawback? Asking as someone who wants to switch from web developer to machine learning.',\n",
       "   'sec': 3598,\n",
       "   'time': '59:58',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"You could probably give a better answer to that. I'm not too knowledgeable in the context of web dev to data science field. But I think anyone who comes from a programming background, if you move into data science, that gives you a good platform to be able to learn programming and engineering as a whole. There's definitely crossover and if you've got more appreciation for the wider parts of the organization that you'd have interaction with – so like UX and UI – and that kind of piece, then yeah. It's never going to do any harm. Is it going to be directly relatable?\",\n",
       "   'sec': 3615,\n",
       "   'time': '1:00:15',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I think what you're asking is — would I look at someone who's come from that background? Or would I think, “Wow, that's great”. I wouldn't. But what I would think is – that's good, because you've probably got a good foundation to learn from. So as long as you've taken the time to learn the other areas in depth then I think that’s always a good thing. But I don't think that will be the thing that will get you the job.\",\n",
       "   'sec': 3662,\n",
       "   'time': '1:01:02',\n",
       "   'who': 'Luke'},\n",
       "  {'header': '“What are the other companies you’re interviewing with?”'},\n",
       "  {'line': \"I would add that it's neither an advantage nor a drawback. It's a good thing, but, like you said, not the thing that will get you the job right. Agunjan is asking, “Is it okay to tell recruiters about other companies you're currently interviewing with?”\",\n",
       "   'sec': 3699,\n",
       "   'time': '1:01:39',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Depends on the recruiter. The reason why a lot of companies do that is because they want to extract information from you to be able to A) gauge where you're at with things. If you're interviewing with me, a company that I work with, and your other companies are Google, Amazon, Facebook and Netflix, and you're interviewing with my company, who's got three people in Hamburg, what's the likelihood of you taking that position? It’s probably quite low.\",\n",
       "   'sec': 3727,\n",
       "   'time': '1:02:07',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"On the other side of that, the old school way of recruitment is that if you tell me when you're interviewing – not me, personally – but I will try and go and get those jobs as clients. So it very much depends on the recruiter that you're working with, and how much you trust that individual. If you think “He wouldn't do that to me. Or she wouldn't do that to me.” If you've got a good relationship there, then there's no reason why you shouldn't… if you can discuss everything, and you can set the landscape about where you're at with things. I believe that being open and transparent is the best thing you can do. If it's a new recruiter off the block, who's just called you and said, “Hey, I've got this job, where else are you interviewing?” Definitely not. The whole recruitment industry is shaking their head at me now and thinking I'm a complete dick. I don’t care.\",\n",
       "   'sec': 3772,\n",
       "   'time': '1:02:52',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Asking for the right salary'},\n",
       "  {'line': \"How impactful is asking salary in the application process? If somebody is asking too low, does it reflect lack of confidence in skills, or shows that this candidate doesn't know the market well enough? What do you think when somebody's asking or a number too low or too high?\",\n",
       "   'sec': 3836,\n",
       "   'time': '1:03:56',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Too low… If someone gave me a salary and it's 10K under what I would classify as market rate, I'd never put that down to confidence… I've never said, “Oh, they must be slightly not confident in their abilities”. My first go to is “Oh, they're underpaid.” Though I don't think it's necessarily bad, going too low. I don't think that's gonna have a negative reaction to your job search if you're under the market value.\",\n",
       "   'sec': 3885,\n",
       "   'time': '1:04:45',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"It depends on how you frame that. If you say, “I'm only worth this,” then that's gonna come down to a competence issue. If it just turns out that you work for a business that has asked you to relocate into Germany, and now you're paid less than what people in the country would be paid. Or if you've joined the grad scheme, and you've worked your way up. There are gonna be lots of different situations like that. I don't think I'm in two minds about the salary thing right now, because originally in my recruitment career, I always wanted to know what people were on.\",\n",
       "   'sec': 3927,\n",
       "   'time': '1:05:27',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Now I'm a little bit more mature, and I don't typically ask “What do you earn right now?” If they want to share that information with me, cool. But I just want to understand what they want from their next role and their next salary. So I don't think it would have a negative connotation. I do think it's a negative thing if you ask for too much. Because then my instinct go-to is “Oh, you're just trying to get tons more money. And that's the main focus.” In the data science and machine learning and AI community right now, there are lots of opportunity for good people to earn a lot of money. But if I see someone who's got six months experience, say, “Yeah, cool, I want 120K,” then I'm like, “you're not quite there yet.” So it's more negative from the other side. Lower is, especially if you're still learning the industry, and you're still learning the role, I don't think it's a negative thing at all.\",\n",
       "   'sec': 3961,\n",
       "   'time': '1:06:01',\n",
       "   'who': 'Luke'},\n",
       "  {'header': 'Summary — what makes a candidate stand out'},\n",
       "  {'line': \"We don't have any more questions. And we are a bit over time. So to summarize or conversation – what makes some candidates really stand out?\",\n",
       "   'sec': 4037,\n",
       "   'time': '1:07:17',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"I thought about this for a while. One thing that really makes candidates stand out to me — it's understanding their purpose, and doubling down on that. Once you do that, everything else becomes easy. If you don't have that, and you're dictated by the market, and you’re like “I'm gonna get a job here. And then hopefully, I'll get one here.” And it’s just a hope that something happens. The candidates that really stand out are looking back at the people that I've worked with, the candidates that I'm like “They are mustard” are the ones that have worked in one – pretty much one – industry, but they've just nailed it. And it's “inch wide mile deep”. That's their focus. In terms of what makes candidates really stand out is having purpose and really working towards that.\",\n",
       "   'sec': 4057,\n",
       "   'time': '1:07:37',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Thanks for coming to this event, for sharing your knowledge and expertise with us. Thanks, Luke.',\n",
       "   'sec': 4131,\n",
       "   'time': '1:08:51',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"No worries. It's a pleasure.\",\n",
       "   'sec': 4140,\n",
       "   'time': '1:09:00',\n",
       "   'who': 'Luke'},\n",
       "  {'line': 'Yeah. So how did it feel being on the other side? Like being a guest in a podcast?',\n",
       "   'sec': 4142,\n",
       "   'time': '1:09:02',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Do you know what I really liked? I love the questions, I think it’s really good. I'll be honest, it was a bit nervous, because this is the first time I've been a guest. Definitely nerve-wracking. Because you want to say stuff that people get value from. And you don't come in and say, “make sure that your font is size 10” or some shit like that. You want to make sure that people can take this stuff, and then actually do it and it actually has impact. How'd you feel like it went? Was that good? I'm not so good.\",\n",
       "   'sec': 4148,\n",
       "   'time': '1:09:08',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I'm still recording by the way.\",\n",
       "   'sec': 4187,\n",
       "   'time': '1:09:47',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': 'Vulnerability is a good skill to have.',\n",
       "   'sec': 4191,\n",
       "   'time': '1:09:51',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"Well, I guess that's all for today. So thanks a lot for coming.\",\n",
       "   'sec': 4196,\n",
       "   'time': '1:09:56',\n",
       "   'who': 'Alexey'},\n",
       "  {'line': \"Awesome. If there's anyone listening who wants to send me direct messages, connect to me on LinkedIn. I'm more than happy to look over your CV, give you any advice that you need, and help you direct what you're trying to do. If anyone needs anything, then please connect to me on LinkedIn.\",\n",
       "   'sec': 4208,\n",
       "   'time': '1:10:08',\n",
       "   'who': 'Luke'},\n",
       "  {'line': \"I'll make sure to put a link to your LinkedIn account in the show notes.\",\n",
       "   'sec': 4226,\n",
       "   'time': '1:10:26',\n",
       "   'who': 'Alexey'}],\n",
       " 'content': '',\n",
       " 'filename': '_podcast/s01e04-standing-out-as-a-data-scientist.md'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_data[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Document chunking utilities for splitting large documents into smaller, overlapping pieces.\n",
    "\n",
    "This module provides functionality to break down documents into chunks using a sliding\n",
    "window approach, which is useful for processing large texts in smaller, manageable pieces\n",
    "while maintaining context through overlapping content.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Any, Dict, Iterable, List\n",
    "\n",
    "\n",
    "def sliding_window(\n",
    "        seq: Iterable[Any],\n",
    "        size: int,\n",
    "        step: int\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Create overlapping chunks from a sequence using a sliding window approach.\n",
    "\n",
    "    Args:\n",
    "        seq: The input sequence (string or list) to be chunked.\n",
    "        size (int): The size of each chunk/window.\n",
    "        step (int): The step size between consecutive windows.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, each containing:\n",
    "            - 'start': The starting position of the chunk in the original sequence\n",
    "            - 'content': The chunk content\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If size or step are not positive integers.\n",
    "\n",
    "    Example:\n",
    "        >>> sliding_window(\"hello world\", size=5, step=3)\n",
    "        [{'start': 0, 'content': 'hello'}, {'start': 3, 'content': 'lo wo'}]\n",
    "    \"\"\"\n",
    "    if size <= 0 or step <= 0:\n",
    "        raise ValueError(\"size and step must be positive\")\n",
    "\n",
    "    n = len(seq)\n",
    "    result = []\n",
    "    for i in range(0, n, step):\n",
    "        batch = seq[i:i+size]\n",
    "        result.append({'start': i, 'content': batch})\n",
    "        if i + size > n:\n",
    "            break\n",
    "\n",
    "    return result\n",
    "\n",
    "def prepare_documents_for_chunking(parsed_data):\n",
    "    \"\"\"\n",
    "    Extract text from transcript field and prepare documents for chunking.\n",
    "    \n",
    "    Args:\n",
    "        parsed_data: List of documents with transcript field containing dialogue\n",
    "        \n",
    "    Returns:\n",
    "        List of documents with extracted text in 'content' field\n",
    "    \"\"\"\n",
    "    prepared_docs = []\n",
    "    \n",
    "    for doc in parsed_data:\n",
    "        # Create a copy of the document\n",
    "        new_doc = doc.copy()\n",
    "        \n",
    "        # Extract text from transcript\n",
    "        transcript_text = \"\"\n",
    "        if 'transcript' in doc and doc['transcript']:\n",
    "            lines = []\n",
    "            for item in doc['transcript']:\n",
    "                if 'line' in item:  # Only get actual dialogue lines, skip headers\n",
    "                    lines.append(item['line'])\n",
    "            transcript_text = \" \".join(lines)\n",
    "        \n",
    "        # Add the extracted text as 'content' field\n",
    "        new_doc['content'] = transcript_text\n",
    "        prepared_docs.append(new_doc)\n",
    "    \n",
    "    return prepared_docs\n",
    "\n",
    "def chunk_documents(\n",
    "        documents: Iterable[Dict[str, str]],\n",
    "        size: int = 30,\n",
    "        step: int = 15,\n",
    "        content_field_name: str = 'content'\n",
    ") -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Split a collection of documents into smaller chunks using sliding windows.\n",
    "\n",
    "    Takes documents and breaks their content into overlapping chunks while preserving\n",
    "    all other document metadata (filename, etc.) in each chunk.\n",
    "\n",
    "    Args:\n",
    "        documents: An iterable of document dictionaries. Each document must have a content field.\n",
    "        size (int, optional): The maximum size of each chunk. Defaults to 2000.\n",
    "        step (int, optional): The step size between chunks. Defaults to 1000.\n",
    "        content_field_name (str, optional): The name of the field containing document content.\n",
    "                                          Defaults to 'content'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of chunk dictionaries. Each chunk contains:\n",
    "            - All original document fields except the content field\n",
    "            - 'start': Starting position of the chunk in original content\n",
    "            - 'content': The chunk content\n",
    "\n",
    "    Example:\n",
    "        >>> documents = [{'content': 'long text...', 'filename': 'doc.txt'}]\n",
    "        >>> chunks = chunk_documents(documents, size=100, step=50)\n",
    "        >>> # Or with custom content field:\n",
    "        >>> documents = [{'text': 'long text...', 'filename': 'doc.txt'}]\n",
    "        >>> chunks = chunk_documents(documents, content_field_name='text')\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for doc in documents:\n",
    "        doc_copy = doc.copy()\n",
    "        doc_content = doc_copy.pop(content_field_name)\n",
    "        chunks = sliding_window(doc_content, size=size, step=step)\n",
    "        for chunk in chunks:\n",
    "            chunk.update(doc_copy)\n",
    "        results.extend(chunks)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the documents\n",
    "prepared_data = prepare_documents_for_chunking(parsed_data)\n",
    "\n",
    "# Now chunk the documents using the extracted content\n",
    "chunks = chunk_documents(prepared_data, size=30, step=15, content_field_name='content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516607"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-bootcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
